{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Understanding (NLU): \n",
    "  * The structures and processes which are useful in making \"computer\" understand the Natural Language.\n",
    "  * Natural Language Understanding (NLU) or Natural Language Interpretation (NLI) is a subtopic of natural language processing in artificial intelligence.\n",
    "  * NLU or NLI is **useful in evaluating the output of** Natural Langauge Generation, Machine Translation, Speech Recognition applicaiotns. \n",
    "\n",
    "&nbsp;\n",
    "  \n",
    "  * **Syntactic Analysis:** looks into the grammer and structure of a sentence (or part of a sentence). Syntactic analysis needs rules of grammer to understand correctness of a sentence. Grametical **Parsing algorithms** are used to generate sentence structure (or a parse tree)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging\n",
    "  * The process of classifying words into their parts of speech and labeling them accordingly is known as part-of-speech tagging, POS-tagging, or simply tagging. Parts of speech are also known as word classes or lexical categories. The collection of tags used for a particular task is known as a tagset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS tagging with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ford', 'NNP'), ('has', 'VBZ'), ('embarked', 'VBN'), ('on', 'IN'), ('an', 'DT'), ('aggressive', 'JJ'), ('strategy', 'NN'), ('for', 'IN'), ('future', 'JJ'), ('profitability', 'NN'), ('and', 'CC'), ('is', 'VBZ'), ('streamlining', 'VBG'), ('the', 'DT'), ('operations', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('global', 'JJ'), ('markets', 'NNS'), ('by', 'IN'), ('reducing', 'VBG'), ('the', 'DT'), ('number', 'NN'), ('of', 'IN'), ('platforms', 'NNS'), ('used', 'VBN'), ('and', 'CC'), ('discontinuing', 'VBG'), ('the', 'DT'), ('products', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('not', 'RB'), ('garnering', 'VBG'), ('good', 'JJ'), ('sales', 'NNS'), ('volume.', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sentence = 'Ford has embarked on an aggressive strategy for future profitability and is streamlining the operations in the global markets by reducing the number of platforms used and discontinuing the products that are not garnering good sales volume.'\n",
    "corpus = sentence.split()\n",
    "print(nltk.pos_tag(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('VBZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NN.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagged Corpora\n",
    "  * Several of the corpora included with NLTK have been tagged for their part-of-speech\n",
    "    * Examples nltk.corpus.brown.tagged_words(), nltk.corpus.nps_chat.tagged_words(), nltk.corpus.treebank.tagged_words(),etc..\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('মহিষের', 'NN'),\n",
       " ('সন্তান', 'NN'),\n",
       " (':', 'SYM'),\n",
       " ('তোড়া', 'NNP'),\n",
       " ('উপজাতি', 'NN'),\n",
       " ('৷', 'SYM'),\n",
       " ('বাসস্থান-ঘরগৃহস্থালি', 'NN'),\n",
       " ('তোড়া', 'NNP'),\n",
       " ('ভাষায়', 'NN'),\n",
       " ('গ্রামকেও', 'NN')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.indian.tagged_words()[:10] # POS tagged corpora are available forfour lanuages Bangla, Hindi, Marathi, and Telugu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('মহিষের', 'NN'), ('সন্তান', 'NN'), (':', 'SYM'), ('তোড়া', 'NNP'), ('উপজাতি', 'NN'), ('৷', 'SYM')], [('বাসস্থান-ঘরগৃহস্থালি', 'NN'), ('তোড়া', 'NNP'), ('ভাষায়', 'NN'), ('গ্রামকেও', 'NN'), ('বলে', 'VM'), ('`', 'SYM'), ('মোদ', 'NN'), (\"'\", 'SYM'), ('৷', 'SYM')], [('মোদের', 'NN'), ('আয়তন', 'NN'), ('খুব', 'INTF'), ('বড়ো', 'JJ'), ('নয়', 'VM'), ('৷', 'SYM')], [('প্রতি', 'QF'), ('মোদে', 'NN'), ('আছে', 'VM'), ('কিছু', 'QF'), ('কুঁড়েঘর', 'NN'), (',', 'SYM'), ('সাধারণ', 'JJ'), ('মহিষশালা', 'NN'), ('৷', 'SYM')], [('আর', 'CC'), ('গ্রামের', 'NN'), ('বাইরে', 'NST'), ('থাকে', 'VM'), ('ডেয়ারি-মন্দির', 'NN'), ('৷', 'SYM')]]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.corpus.indian.tagged_sents()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bangla.pos', 'hindi.pos', 'marathi.pos', 'telugu.pos']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.indian.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('4', 'QFNUM'), ('.', 'SYM'), ('ఆడిట్', 'NN'), ('నిర్వహణ', 'NN'), ('ఆడిటర్', 'NN'), ('ఒక', 'QFNUM'), ('కొత్త', 'JJ'), ('ఆడిట్', 'NN'), ('చేపట్టే', 'VRB'), ('ముందు', 'PREP'), ('సక్రమ', 'JJ'), ('పద్ధతి', 'NN'), ('లో', 'PREP'), ('కార్య', 'JJ'), ('ప్రణాళికను', 'NN'), ('రూపొందించాలి', 'VFM'), ('.', 'SYM'), ('దాని', 'PRP'), ('కనుగుణంగా', 'PREP'), ('వ్యవహరించాలి', 'VFM')]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.corpus.indian.tagged_words(fileids='telugu.pos')[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('4', 'QFNUM'), ('.', 'SYM')], [('ఆడిట్', 'NN'), ('నిర్వహణ', 'NN'), ('ఆడిటర్', 'NN'), ('ఒక', 'QFNUM'), ('కొత్త', 'JJ'), ('ఆడిట్', 'NN'), ('చేపట్టే', 'VRB'), ('ముందు', 'PREP'), ('సక్రమ', 'JJ'), ('పద్ధతి', 'NN'), ('లో', 'PREP'), ('కార్య', 'JJ'), ('ప్రణాళికను', 'NN'), ('రూపొందించాలి', 'VFM'), ('.', 'SYM')], [('దాని', 'PRP'), ('కనుగుణంగా', 'PREP'), ('వ్యవహరించాలి', 'VFM'), ('.', 'SYM')], [('పత్రసహిత', 'JJ'), ('సాక్ష్యాధారాల', 'NN'), ('తో', 'PREP'), (',', 'SYM'), ('వ్యవహారాల', 'NN'), ('ను', 'PREP'), ('తనిఖీ', 'NVB'), ('చేయాలి', 'VFM'), ('.', 'SYM')], [('ఆడిట్', 'NVB'), ('చేసే', 'VJJ'), ('విధానం', 'NN'), ('సంస్థ', 'NN'), ('అవసరాల', 'NN'), ('ను', 'PREP'), ('బట్టి', 'CC'), (',', 'SYM'), ('అంతర్గత', 'JJ'), ('తనిఖీన్', 'NN'), ('బట్టి', 'CC'), (',', 'SYM'), ('ఇంకా', 'CC'), ('అనేక', 'QF'), ('ఇతర', 'JJ'), ('విషయాల', 'NN'), ('ను', 'PREP'), ('బట్టి', 'CC'), ('మారుతూఉంటుంది', 'VAUX'), ('.', 'SYM')]]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.corpus.indian.tagged_sents(fileids='telugu.pos')[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpaCy, a production ready framework for NLP tasks\n",
    "  * Non-destructive tokenization\n",
    "  * Named entity recognition\n",
    "  * Support for 49+ languages\n",
    "  * 16 statistical models for 9 languages\n",
    "  * Pre-trained word vectors\n",
    "  * State-of-the-art speed\n",
    "  * Easy deep learning integration\n",
    "  * Part-of-speech tagging\n",
    "  * Labelled dependency parsing\n",
    "  * Syntax-driven sentence segmentation\n",
    "  * Built in visualizers for syntax and NER\n",
    "  * Convenient string-to-hash mapping\n",
    "  * Export to numpy data arrays\n",
    "  * Efficient binary serialization\n",
    "  * Easy model packaging and deployment\n",
    "  * Robust, rigorously evaluated accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging with SpaCy: \n",
    "  * https://spacy.io/api/annotation#pos-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple - PROPN - nsubj\n",
      "is - AUX - aux\n",
      "looking - VERB - ROOT\n",
      "at - ADP - prep\n",
      "buying - VERB - pcomp\n",
      "U.K. - PROPN - compound\n",
      "startup - NOUN - dobj\n",
      "for - ADP - prep\n",
      "$ - SYM - quantmod\n",
      "1 - NUM - compound\n",
      "billion - NUM - pobj\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # download small model -> python -m spacy download en_core_web_sm\n",
    "doc = nlp(u\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text, '-', token.pos_, '-', token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntactic Analysis - Sentence Structure and Parsers\n",
    "\n",
    "#### Context Free Grammer (CFG or Constituency Grammer or Phrase Structure Grammer):  \n",
    "  * Context free grammer is defined as four tuples G = {$V, \\sum, S, P$}.\n",
    "    * V = Set of variables or Non-Terminal symbols\n",
    "    * $\\sum$ = Set of Terminal symbols\n",
    "    * S = Start symbols\n",
    "    * P = \"Production rules\" : A -> $\\alpha$ where $\\alpha$ = $\\{V U \\sum\\}^*$ and A $\\epsilon$ V\n",
    "  <img src=\"img_nlp/cfg.png\" width=700/>  \n",
    "  \n",
    "      * Example to generate a sentence \"I like football\". Given set of nouns and verbs. N = {I|HE|SHE|BOY|GIRL|CRICKET|FOOTBALL}, V={LIKE|READ|SING}.\n",
    "        * The production rules are as below \n",
    "          * R1: S -> NP VP\n",
    "          * R2: NP -> N\n",
    "          * R3: VP -> V NP\n",
    "          * R4: VP -> V\n",
    "        \n",
    "   <img src=\"img_nlp/cfg_example.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'an' | 'my'\n",
    "N -> 'elephant' | 'pajamas'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
    "parser = nltk.ChartParser(groucho_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "for tree in parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A parser processes input sentences according to the productions of a grammar, and builds one or more constituent structures that conform to the grammar.\n",
    "* **Recursive Descent Parser Demo (simulator) - nltk.app.rdparser():** This tool allows you to watch the operation of a recursive descent parser as it grows the parse tree and matches it against the input words. \"The dog saw a man in the park\". The tree recursively expands, hence it is called as REcursive Descent Parser.\n",
    "\n",
    "* **Recursive Grammer:** A grammar is said to be recursive if a category occurring on the left hand side of a production also appears on the righthand side of a production.\n",
    "  * Direct Recursion : The production Nom -> Adj Nom (where Nom is the category of nominals) \n",
    "  * Indirect Recursion : S arises from the combination of two productions, namely S -> NP VP and VP -> V S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.app.rdparser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Shift-Reduce Parsing Demo (simulator) - nltk.app.srparser():** The shift-reduce parser repeatedly pushes the next input word onto a stack; this is the shift operation. If the top n items on the stack match the n items on the right hand side of some production, then they are all popped off the stack, and the item on the left-hand side of the production is pushed on the stack. This replacement of the top n items with a single item is the reduce operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: VP -> V NP PP will never be used\n"
     ]
    }
   ],
   "source": [
    "nltk.app.srparser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependency Parsing:\n",
    "  * Dependency grammar, focusses instead on how words relate to other words. Dependency is a binary asymmetric relation that holds between a head and its dependents. The head of a sentence is usually taken to be the tensed verb, and every other word is either dependent on the sentence head, or connects to it through a path of dependencies.\n",
    "\n",
    "  * A dependency representation is a labeled directed graph, where the nodes are the lexical items and the labeled arcs represent dependency relations from heads to dependents. Below diagram illustrates dependency graph, where arrows point from heads to their dependents.\n",
    "  \n",
    "<img src=\"img_nlp/depgraph0.png\" />\n",
    "\n",
    "  * The arcs are labeled with the grammatical function that holds between a dependent and its head. For example, I is the SBJ (subject) of shot (which is the head of the whole sentence), and in is an NMOD (noun modifier of elephant).\n",
    "  * Here's one way of encoding a dependency grammar in NLTK — note that it only captures bare dependency information without specifying the type of dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "groucho_dep_grammar = nltk.DependencyGrammar.fromstring(\"\"\"\n",
    "'shot' -> 'I' | 'elephant' | 'in'\n",
    "'elephant' -> 'an' | 'in'\n",
    "'in' -> 'pajamas'\n",
    "'pajamas' -> 'my'\n",
    "\"\"\")\n",
    "pdp = nltk.ProjectiveDependencyParser(groucho_dep_grammar)\n",
    "sent = 'I shot an elephant in my pajamas'.split()\n",
    "trees = pdp.parse(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(shot I (elephant an (in (pajamas my))))\n",
      "(shot I (elephant an) (in (pajamas my)))\n"
     ]
    }
   ],
   "source": [
    "for tree in trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"bc7bf8b41ed34dcb89867ad0fbbbce31-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">looking</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">buying</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">startup</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">1</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">billion</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-5\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,266.5 L1103.0,254.5 1087.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-6\" stroke-width=\"2px\" d=\"M770,264.5 C770,2.0 1275.0,2.0 1275.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,266.5 L1283.0,254.5 1267.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-9\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,2.0 1800.0,2.0 1800.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc7bf8b41ed34dcb89867ad0fbbbce31-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,266.5 L1808.0,254.5 1792.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # download small model -> python -m spacy download en_core_web_sm\n",
    "doc = nlp(u\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"910caf757ee04461a656550945f09a99-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">am</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">traveling</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">from</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Hyderabad</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Bangalore</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-910caf757ee04461a656550945f09a99-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-910caf757ee04461a656550945f09a99-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-910caf757ee04461a656550945f09a99-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-910caf757ee04461a656550945f09a99-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-910caf757ee04461a656550945f09a99-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-910caf757ee04461a656550945f09a99-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-910caf757ee04461a656550945f09a99-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-910caf757ee04461a656550945f09a99-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-910caf757ee04461a656550945f09a99-0-4\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-910caf757ee04461a656550945f09a99-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,266.5 L933.0,254.5 917.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-910caf757ee04461a656550945f09a99-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-910caf757ee04461a656550945f09a99-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1090.0,266.5 L1098.0,254.5 1082.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "travel = 'I am traveling from Hyderabad to Bangalore'\n",
    "travel_doc = nlp(travel)\n",
    "displacy.render(travel_doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token :  I\n",
      "**********\n",
      "Ancestor :  traveling\n",
      "POS tags :  VERB\n",
      "\n",
      "----------\n",
      "token :  am\n",
      "**********\n",
      "Ancestor :  traveling\n",
      "POS tags :  VERB\n",
      "\n",
      "----------\n",
      "token :  traveling\n",
      "**********\n",
      "----------\n",
      "token :  from\n",
      "**********\n",
      "Ancestor :  traveling\n",
      "POS tags :  VERB\n",
      "\n",
      "----------\n",
      "token :  Hyderabad\n",
      "**********\n",
      "Ancestor :  from\n",
      "POS tags :  ADP\n",
      "\n",
      "Ancestor :  traveling\n",
      "POS tags :  VERB\n",
      "\n",
      "----------\n",
      "token :  to\n",
      "**********\n",
      "Ancestor :  traveling\n",
      "POS tags :  VERB\n",
      "\n",
      "----------\n",
      "token :  Bangalore\n",
      "**********\n",
      "Ancestor :  to\n",
      "POS tags :  ADP\n",
      "\n",
      "Ancestor :  traveling\n",
      "POS tags :  VERB\n",
      "\n",
      "----------\n",
      "Named Entities:  Hyderabad\n",
      "Named Entities:  Bangalore\n"
     ]
    }
   ],
   "source": [
    "for token in travel_doc:\n",
    "    print('token : ', token)\n",
    "    print(10*'*')\n",
    "    for a in token.ancestors:\n",
    "        print(\"Ancestor : \", a)\n",
    "        print(\"POS tags : \", a.pos_)\n",
    "        print()\n",
    "    print(10*'-')\n",
    "    \n",
    "for ent in travel_doc.ents:\n",
    "    print(\"Named Entities: \", ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * the parser is loaded and enabled as part of the standard processing pipeline. If you don’t need any of the syntactic information, you should disable the parser. Disabling the parser will make spaCy load and run much faster. If you want to load the parser, but need to disable it for specific documents, you can also control its use on the nlp object.\n",
    "    * nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\"])\n",
    "    * doc = nlp(u\"I don't want parsed\", disable=[\"parser\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence Segmentation\n",
    "  * A Doc object’s sentences are available via the Doc.sents property. **Unlike other libraries, spaCy uses the dependency parse to determine sentence boundaries.** This is usually more accurate than a rule-based approach, but it also means you’ll need a statistical model and accurate predictions. If your texts are closer to general-purpose news or web text, this should work well out-of-the-box.\n",
    "  * For social media or conversational text that doesn’t follow the same rules, your application may benefit from a custom rule-based implementation. You can either use the built-in Sentencizer or plug an entirely custom rule-based function into your processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n",
      "This is another sentence.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"This is a sentence. This is another sentence.\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * Custom rule-based stratagy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: ['this is a sentence...hello...and another sentence.']\n"
     ]
    }
   ],
   "source": [
    "text = u\"this is a sentence...hello...and another sentence.\"\n",
    "doc = nlp(text)\n",
    "print(\"Before:\", [sent.text for sent in doc.sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After: ['this is a sentence...', 'hello...', 'and another sentence.']\n"
     ]
    }
   ],
   "source": [
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == \"...\":\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(set_custom_boundaries, before=\"parser\")\n",
    "doc = nlp(text)\n",
    "print(\"After:\", [sent.text for sent in doc.sents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Entity Recognition\n",
    "  * spaCy features an extremely fast statistical entity recognition system, that assigns labels to contiguous spans of tokens. The default model identifies a variety of named and numeric entities, including companies, locations, organizations and products. You can add arbitrary classes to the entity recognition system, and update the model with new examples.\n",
    "  * A named entity is a “real-world object” that’s assigned a name – for example, a person, a country, a product or a book title. spaCy can recognize various types of named entities in a document, by asking the model for a prediction. Because models are statistical and strongly depend on the examples they were trained on, this doesn’t always work perfectly and might need some tuning later, depending on your use case.\n",
    "\n",
    "  * Named entities are available as the **ents** property of a **Doc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "doc = nlp(u\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is looking at buying \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " startup for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    $1 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * doc.ents is the standard way to access **entity annotations** such as \"text\", \"start_char\", \"end_char\", \"label_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('San Francisco', 0, 13, 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"San Francisco considers banning sidewalk delivery robots\")\n",
    "\n",
    "# document level\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San\n"
     ]
    }
   ],
   "source": [
    "print(doc[0]) # token at index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Francisco\n"
     ]
    }
   ],
   "source": [
    "print(doc[1]) # token at index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San\n",
      "Francisco\n",
      "considers\n",
      "banning\n",
      "sidewalk\n",
      "delivery\n",
      "robots\n"
     ]
    }
   ],
   "source": [
    "for t in doc:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * doc[index] object will have **token entity annotations** such as \"text\", \"ent_iob_\"  (iob: inside|outside|between), \"ent_type_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['San', 'B', 'GPE']\n",
      "['Francisco', 'I', 'GPE']\n",
      "['considers', 'O', '']\n"
     ]
    }
   ],
   "source": [
    "# token level\n",
    "ent_san = [doc[0].text, doc[0].ent_iob_, doc[0].ent_type_]\n",
    "ent_francisco = [doc[1].text, doc[1].ent_iob_, doc[1].ent_type_]\n",
    "out_side = [doc[2].text, doc[2].ent_iob_, doc[2].ent_type_]\n",
    "print(ent_san)  # [u'San', u'B', u'GPE']\n",
    "print(ent_francisco)  # [u'Francisco', u'I', u'GPE']\n",
    "print(out_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['considers', '', '']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc[2].text, doc[2].ent_iob_, doc[2].ent_type_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Named Entity Annotation (Custom tagging):**  In below text we expect SpaCy to identify \"FB\" as named entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before []\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"FB is hiring a new Vice President of global policy\")\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print('Before', ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * **adding FB to named entities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "ORG = doc.vocab.strings[u\"ORG\"]  # get hash value of entity label\n",
    "PERSON = doc.vocab.strings[u\"PERSON\"]\n",
    "fb_ent = Span(doc, 0, 1, label=ORG) # create a Span for the new entity\n",
    "fb_ent1= Span(doc, 5, 7, label=PERSON)\n",
    "doc.ents = list(doc.ents) + [fb_ent, fb_ent1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * Now recognizes FB as named entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After [('FB', 0, 2, 'ORG'), ('Vice President', 19, 33, 'PERSON')]\n"
     ]
    }
   ],
   "source": [
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print('After', ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After further modifications [('FB', 0, 2, 'ORG'), ('FB', 52, 54, 'ORG'), ('Facebook', 81, 89, 'PERSON')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"FB is hiring a new Vice President of global policy. FB is a abbreviated word for Facebook\")\n",
    "fb_ent = Span(doc, 0, 1, label=ORG) # create a Span for the new entity\n",
    "doc.ents = list(doc.ents) + [fb_ent]\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print('After further modifications', ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule-based entity recognition V2.1\n",
    "  * The **EntityRuler** is an exciting new component that lets you add named entities based on pattern dictionaries, and makes it easy to combine rule-based and statistical named entity recognition for even more powerful models.\n",
    "  * **Entity Patterns:** Entity patterns are dictionaries with two keys: \n",
    "    * **\"label\":** specifying the label to assign to the entity if the pattern is matched.\n",
    "    * **\"pattern\":** the match pattern. \n",
    "  * The entity ruler accepts two types of patterns:\n",
    "    * **Phrase patterns** for exact string matches (string).\n",
    "      * {\"label\":\"ORG\", \"pattern\":\"Apple\"}\n",
    "    * **Token Patterns** with one dictionary describing one token (list). \n",
    "      * {\"label\":\"GPE\", \"pattern\":\\[{\"lower\":\"san\"}, {\"lower\":\"francisci\"}\\]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('FB', 'ABC'), ('FB', 'ABC')]\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "nlp = English()\n",
    "ruler = EntityRuler(nlp)\n",
    "patterns = [{\"label\": \"ABC\", \"pattern\": \"FB\"}]\n",
    "ruler.add_patterns(patterns)\n",
    "nlp.add_pipe(ruler)\n",
    "\n",
    "doc = nlp(u\"FB is hiring a new Vice President of global policy. FB is a abbreviated word for Facebook\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('FB', 'ORG'), ('FB', 'ORG'), ('Facebook', 'PERSON')]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "ruler = EntityRuler(nlp)\n",
    "patterns = [{\"label\": \"ORG\", \"pattern\": \"FB\"}]\n",
    "ruler.add_patterns(patterns)\n",
    "nlp.add_pipe(ruler)\n",
    "\n",
    "doc = nlp(u\"FB is hiring a new Vice President of global policy. FB is a abbreviated word for Facebook\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    FB\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is hiring a new Vice President of global policy. \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    FB\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is a abbreviated word for \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Facebook\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('san franciSci', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "nlp = English()\n",
    "ruler = EntityRuler(nlp)\n",
    "patterns = [{\"label\":\"GPE\", \"pattern\":[{\"lower\":\"san\"}, {\"lower\":\"francisci\"}]}]\n",
    "ruler.add_patterns(patterns)\n",
    "nlp.add_pipe(ruler)\n",
    "\n",
    "doc = nlp(u\"FB is has an office in san franciSci. FB is a abbreviated word for Facebook\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Using entities, part-of-speech tags and the dependency parse, refer to https://spacy.io/usage/rule-based-matching#models-rules-pos-dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">FB is has an office in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    San Francisci\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". FB is a abbreviated word for Facebook</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * **Semantic Analysis:** focuses on meaning of sentences, phrases, paragraphs or even documents. Symantic analysis is heavily used in **Word Sense Disambiguation (WSD)** (word2vec is very useful in understing sematic similarities)\n",
    "  * **Lexical Semantics:** focuses on understing meaning of words, sub-words, compound words and phrases.\n",
    "    * **Hyponymy, Hypernym, Hyponyms: Hyponymy** describes relationship between \"Generic Term\" and its \"Specific Instances\". Here generic term is called as **Hypernym** specific instances are called as **Hyponyms**.\n",
    "    * **Homonymy:** Homonymys are the words with same spelling or syntax but have different meaning.\n",
    "      * Example: bear (an animal)/bear (to withstand or hold up), can (a metal container)/can (able to)\n",
    "    * **Polysemy:** is an aspect of semantic ambiguity that concerns the multiplicity of word meanings.\n",
    "      * Example: consider the meaning of the adjective good in the following sentences:\n",
    "        * We had a good time yesterday. (good - meaning - pleasurable/enjoyable/satisfying)\n",
    "        * That ticket is good for travel on any flight. (good - meaning - generally valid and acceptable.)  \n",
    "          \n",
    "&nbsp;          \n",
    "          \n",
    "  * **Handling Ambiguties:** First we need to understand different kinds of ambiguties and how to handle them. There are four kinds of ambiguties, namely 1) lexical ambiguity, 2) Syntactic ambiguity, 3) Semantic ambiguity and 4) Pragmatic ambiguity.\n",
    "    * **Lexical ambiguity:** is the presence of two or more possible meanings within a single word. Also called **semantic ambiguity** or **homonymy**.\n",
    "      * Example: I saw a bird (saw - verb), The saw machine is useful in cutting wood (saw - noun).\n",
    "      * **How to fix:** proper POS tagging can fix this issue. On top of POS tagging, we can use WordNet sense, it has got various senses for words with different POS tags.\n",
    "    * **Syntactic ambiguity:** there can be different way of interpreting sequence of words. This is also known as **Prepositional Phrase(PP) ambiguity**. (The preposition “on” in “The keys are on the table” shows location. The preposition “in” in “The movie starts in one hour” shows time.)\n",
    "      * Example: \"The man saw the girl with the telescope\" - this sentence can be interpreted in two ways \n",
    "        * 1) \"the man saw the girl - with the telescope -\" or \n",
    "        * 2) \"the man saw - the girl with - the telescope\".\n",
    "          * **How to fix:** need to calculate log-likelyhood ratio of ratio between (co-occurence) \"probability of preposition preceded by verb\" and \"preposition preceded by noun\".\n",
    "            * F(v, n, p) = log $\\frac{P(p/v)}{P(p/n)}$ \n",
    "              * if F(v, n, p) < 0 then attach \"preposition\" with \"noun\"\n",
    "              * if F(v, n, p) > 0 then attach \"preposition\" with \"verb\"\n",
    "    * **Semantic ambiguity:** happens when the meaning of the words themselves can be misinterpreted.\n",
    "      * Example: ABC head seeks arms. Here, head - can be understood as owner or body part. arms - can be understood as weapons or body parts.\n",
    "      * **How to fix:** Handling semantic ambiguity with high accuracy is an open research area. The word2vec representation technique is very useful in handling semantic ambiguity.\n",
    "    * **Pragmatic ambiguity:** is defined as \"the context of a phrase gives multiple interpretations\". Pragrmatic ambiguity is still an open area of research. \n",
    "      * Example I have pens and books, give it to that boy. Here the amiguity is about which one to give.\n",
    "    * **Discourse Integration:** deals with how immediatly preceding sentence affect the meaning and interpretation of the next sentnece. The context can be at paragraph level or docuemnt level. Discourse Integration is useful in NLG applications such as Chatbots.\n",
    "    * **Pragmatic Analysis:** Pragmatic analysis deals with outside word knowledge, the knowledge that is external to the document and/or query.\n",
    "      * Example: \"Pruning tree is a long process\". Here we are talking about tree pruning in computer science algorithm context not interms of cutting physical tree. The statment is ambiguous. This kind of ambiguity is still an open area of research.    \n",
    "  \n",
    "  \n",
    "## Natural-language generation (NLG):\n",
    "  * The probabilistic/rule based models which make \"computer\" generate natural lanuge. \n",
    "  * It can be used to produce long form content for organizations to automate custom reports, as well as produce custom content for a web or mobile application. It can also be used to generate short blurbs of text in interactive conversations (a chatbot) which might even be read out loud by a text-to-speech system.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
