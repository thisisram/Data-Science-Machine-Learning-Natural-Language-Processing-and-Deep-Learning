{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = pd.read_csv('../data/digit_recognizer_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.iloc[:, 1:]\n",
    "y = digits.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit = X_train.loc[6635]\n",
    "some_digit_image = some_digit.values.reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from  matplotlib.cm import  binary\n",
    "#plt.figure(figsize=(10,10))\n",
    "plt.imshow(some_digit_image, cmap = binary,\n",
    "           interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(y_train.loc[6635])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train = X_train.astype(np.float64)\n",
    "X_test = X_test.astype(np.float64)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y variable one-hot conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test_cat = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37800, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22460    8\n",
       "20828    5\n",
       "32032    6\n",
       "6194     2\n",
       "12768    2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape X variable to 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37800, 28, 28, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4200, 28, 28, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CNN model with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.layers import Conv2D as Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = keras.Sequential()\n",
    "\n",
    "cnn_model.add(keras.layers.Conv2D(input_shape=(28, 28, 1), activation=tf.nn.relu, filters=3, \\\n",
    "                     kernel_size=3, strides=1, padding='valid'))\n",
    "\n",
    "cnn_model.add(keras.layers.Conv2D(activation=tf.nn.relu, filters=6, \\\n",
    "                     kernel_size=5, strides=1, padding='valid'))\n",
    "\n",
    "cnn_model.add(keras.layers.Conv2D(activation=tf.nn.relu, filters=12, \\\n",
    "                     kernel_size=7, strides=1, padding='valid'))\n",
    "\n",
    "cnn_model.add(keras.layers.Conv2D(activation=tf.nn.relu, filters=24, \\\n",
    "                     kernel_size=9, strides=1, padding='valid'))\n",
    "\n",
    "cnn_model.add(keras.layers.Flatten())\n",
    "cnn_model.add(keras.layers.Dense(216, activation='relu'))\n",
    "#cnn_model.add(Dropout(rate=0.5))\n",
    "cnn_model.add(keras.layers.Dense(108, activation='relu'))\n",
    "cnn_model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 2362 steps, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "2362/2362 [==============================] - 84s 35ms/step - loss: 0.6599 - accuracy: 0.7859 - val_loss: 0.1533 - val_accuracy: 0.9538\n",
      "Epoch 2/10\n",
      "2362/2362 [==============================] - 83s 35ms/step - loss: 0.2607 - accuracy: 0.9199 - val_loss: 0.1061 - val_accuracy: 0.9638\n",
      "Epoch 3/10\n",
      "2362/2362 [==============================] - 83s 35ms/step - loss: 0.1875 - accuracy: 0.9413 - val_loss: 0.0944 - val_accuracy: 0.9683\n",
      "Epoch 4/10\n",
      "2362/2362 [==============================] - 83s 35ms/step - loss: 0.1559 - accuracy: 0.9518 - val_loss: 0.0722 - val_accuracy: 0.9774\n",
      "Epoch 5/10\n",
      "2362/2362 [==============================] - 84s 36ms/step - loss: 0.1325 - accuracy: 0.9585 - val_loss: 0.0629 - val_accuracy: 0.9805\n",
      "Epoch 6/10\n",
      "2362/2362 [==============================] - 81s 34ms/step - loss: 0.1158 - accuracy: 0.9638 - val_loss: 0.0615 - val_accuracy: 0.9807\n",
      "Epoch 7/10\n",
      "2362/2362 [==============================] - 82s 35ms/step - loss: 0.1074 - accuracy: 0.9664 - val_loss: 0.0591 - val_accuracy: 0.9831\n",
      "Epoch 8/10\n",
      "2362/2362 [==============================] - 81s 34ms/step - loss: 0.0973 - accuracy: 0.9705 - val_loss: 0.0565 - val_accuracy: 0.9826\n",
      "Epoch 9/10\n",
      "2362/2362 [==============================] - 82s 35ms/step - loss: 0.0917 - accuracy: 0.9720 - val_loss: 0.0535 - val_accuracy: 0.9840\n",
      "Epoch 10/10\n",
      "2362/2362 [==============================] - 81s 34ms/step - loss: 0.0843 - accuracy: 0.9733 - val_loss: 0.0777 - val_accuracy: 0.9774\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.0001)\n",
    "\n",
    "# look for monitor values at https://keras.io/callbacks/\n",
    "#learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "data_augmentor = keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range=10,\n",
    "            zoom_range=0.1,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1)\n",
    "\n",
    "# propar values for loss are present at https://keras.io/losses/\n",
    "cnn_model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = cnn_model.fit(data_augmentor.flow(X_train, y_train_cat, batch_size=16), epochs=epochs,\n",
    "                                    validation_data=(X_test, y_test_cat), verbose=1,\n",
    "                                    steps_per_epoch=X_train.shape[0]//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_model_json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-119234039c28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msave_model_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'first_keras_model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'save_model_json' is not defined"
     ]
    }
   ],
   "source": [
    "save_model_json(cnn_model, 'first_keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_h5(cnn_model, 'first_keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit_transformed = some_digit_image.reshape((-1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_h5_model('./models/first_keras_model.h5', './models/first_keras_model.json')\n",
    "#model = load_json_model('./models/model.json')\n",
    "print(\"model predict : \",model.predict(some_digit_transformed))\n",
    "print(\"model classes : \",model.predict_classes(some_digit_transformed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model as h5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "\n",
    "#model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "#model = load_model('my_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
