{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier\n",
    "  * Suppose you have trained a few classifiers, each one individually achieving about 80% accuracy (Logistic Regression classifier, an SVM classifier, a Random Forest classifier, a K-Nearest Neighbors classifier). We can create a better classifier by **aggregating the predictions** of each classifier **and predict the class that gets the most votes.** This approach is called as Voting Classification.\n",
    "  \n",
    "**Hard Voting Classifier : ** Aggregate predections of each classifier and predict the class that gets most votes. This is called as **\"majority - voting\" or \"Hard - voting\"** classifier.\n",
    "\n",
    "  <img src='../img/hard_voting.png' />\n",
    " \n",
    "**Soft Voting Classifier : ** In an ensemble model, all classifiers (algorithms) are able to estimate class probabilities (i.e., they all have predict_proba() method), then we can specify Scikit-Learn to predict the class with the highest probability, averaged over all the individual classifiers. \n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th> Modle Name </th>\n",
    "        <th> Class - 1 Probability</th>\n",
    "        <th> Class - 0 Probability</th>\n",
    "    </tr>   \n",
    "    <tr>\n",
    "        <td> Model - 1 </td>\n",
    "        <td> 0.49 </td>\n",
    "        <td> 0.51 </td>\n",
    "    </tr>   \n",
    "    <tr>\n",
    "        <td> Model - 2 </td>\n",
    "        <td> 0.99 </td>\n",
    "        <td> 0.01 </td>\n",
    "    </tr>  \n",
    "    <tr>\n",
    "        <td> Model - 3 </td>\n",
    "        <td> 0.49 </td>\n",
    "        <td> 0.51 </td>\n",
    "    </tr>    \n",
    "    <tr>\n",
    "        <td> <b>Averages</b> </td>\n",
    "        <td> <b> <font color=\"green\">0.66</font></b> </td>\n",
    "        <td> <b> <font color=\"red\">0.34</font></b> </td>\n",
    "    </tr>   \n",
    "</table>\n",
    "This soft-voting classifier often work better than hard-voting as it gives more weight to highly confident votes. Need to specify **voting=\"soft\"** and ensure that all classifiers can estimate class probabilities.\n",
    "  * One algorithm where we need to be careful is SVC, by default SVC will not give probabilities, we have to specify \"probability\" hyperparameter to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     ccp_alpha=0.0,\n",
       "                                                     class_weight=None,\n",
       "                                                     crit...\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=42, verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             ('svc',\n",
       "                              SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                  class_weight=None, coef0=0.0,\n",
       "                                  decision_function_shape='ovr', degree=3,\n",
       "                                  gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                                  probability=False, random_state=42,\n",
       "                                  shrinking=True, tol=0.001, verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(random_state=42)\n",
    "\n",
    "hard_voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)], voting='hard')\n",
    "hard_voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "Hard voting clasifier accuracy:  0.912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "            \n",
    "hvc_predict = hard_voting_clf.predict(X_test)            \n",
    "print(\"Hard voting clasifier accuracy: \", accuracy_score(y_test, hvc_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     ccp_alpha=0.0,\n",
       "                                                     class_weight=None,\n",
       "                                                     crit...\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=42, verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             ('svc',\n",
       "                              SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                  class_weight=None, coef0=0.0,\n",
       "                                  decision_function_shape='ovr', degree=3,\n",
       "                                  gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                                  probability=True, random_state=42,\n",
       "                                  shrinking=True, tol=0.001, verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(probability=True, random_state=42)\n",
    "\n",
    "soft_voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft')\n",
    "soft_voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "VotingClassifier 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, soft_voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging and Pasting:\n",
    "  * In Bagging or Pasting ensemble model use same training algorithm, but train them on different random sub-sets of the training set.\n",
    "  * **Bagging : ** When **sampling** is performed **with replacement**, we call it as **Bagging**.\n",
    "  * **Pasting : ** When **sampling** is performed **without replacement**, we call it as **Pasting**.\n",
    "  <table>  \n",
    "    <tr>\n",
    "        <td> <img src=\"../img/bagging.bmp\" alt=\"Bagging\" style=\"width: 500px;\"/> </td>\n",
    "        <td> <img src=\"../img/pasting.bmp\" alt=\"Pasting\" style=\"width: 500px;\"/> </td>\n",
    "    </tr>\n",
    "   </table> \n",
    "  * Once all predictors are trained, the ensemble can make a **prediction for a new instance** by simply aggregating the predictions of all predictors. The aggregation function is typically the statistical mode (i.e., the most frequent prediction, **just like a hard voting classifier**) for classification, or **the average for regression.**\n",
    "  * **Bagging and Pasting are scalable :** Predictors can all be trained in parallel, via different CPU cores or even different servers. Similarly, predictions can be made in parallel. This is one of the reasons why bagging and pasting are such popular methods, they scale very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "    max_samples=100, bootstrap=False, random_state=42)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856\n"
     ]
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_bag_clf = BaggingClassifier(\n",
    "    LogisticRegression(random_state=42), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1, random_state=42)\n",
    "lr_bag_clf.fit(X_train, y_train)\n",
    "lr_y_pred = lr_bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, lr_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-Bag Evaluation\n",
    "  * **Out-of-Bag instaces : ** With Bagging, the sampling technique is Bootstraping. This sampling is done with replacement. This means, some instances are sampled many times and some are not at all sampled. Suppore about 63% of the data is sampled for each predictor, remaining 37% is called as **Out-of_Bag samples** for the predictor. Similary for all predictors in Bagging model, there will be out-of-bag samples.\n",
    "  * We can use these out-of-bag samples (a **separate** unseen dataset for **each predictor**) as cross-validation set.\n",
    "  * We can do this in Scikit-Learn BaggingClassifier using, oob_score (out-of-bag score) hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9013333333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "    bootstrap=True, n_jobs=-1, oob_score=True, random_state=40)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### oob_decision_function_ is returning calss probabilities as the base esitmator (DecisionTree) has got predict_proba() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31746032, 0.68253968],\n",
       "       [0.34117647, 0.65882353],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "  * Random Forest is an ensemble model of DecisionTrees. Random Forest picks up a sub-set of features  randomly and searches for best feature amoung the sub-set.\n",
    "  * With a few exceptions, a RandomForestClassifier has all the hyperparameters of a DecisionTreeClassifier (to control how trees are grown), plus all the hyperparameters of a BaggingClassifier to control the ensemble itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)  \n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = rnd_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "  * if you look at a single Decision Tree, important features are likely to appear closer to the root of the tree, while unimportant features will often appear closer to the leaves (or not at all). It is therefore possible to get an estimate of a feature’s importance by computing the average depth at which it appears across all trees in the forest. Scikit-Learn computes this automatically for every feature after training. You can access the result using the feature\\_importances\\_ variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_dataset = pd.read_csv('../Data/digit_recognizer_train.csv')\n",
    "digit_X = digit_dataset.iloc[:, 1:]\n",
    "digit_y = digit_dataset['label']\n",
    "digit_X_train, digit_X_test, digit_y_train, digit_y_test = \\\n",
    "                                    train_test_split(digit_X, digit_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "rnd_clf.fit(digit_X_train, digit_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 6.47398142e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.91867187e-06,\n",
       "       5.49643294e-06, 2.54335439e-06, 2.52758119e-06, 3.39500928e-06,\n",
       "       2.35267345e-06, 1.21392748e-06, 1.21886346e-06, 2.46435557e-06,\n",
       "       1.18632348e-06, 1.08274058e-06, 1.12574693e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.58554634e-06, 2.60396527e-06, 4.51070792e-06,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       6.48452266e-07, 0.00000000e+00, 1.26513769e-06, 7.07745484e-06,\n",
       "       1.88582447e-05, 1.72547953e-05, 5.57766107e-05, 9.73217446e-05,\n",
       "       2.32614482e-04, 9.10672645e-05, 1.77173348e-04, 1.57657795e-04,\n",
       "       1.32580369e-04, 1.87185667e-04, 1.16262880e-04, 3.45927414e-05,\n",
       "       3.09671148e-05, 7.01754714e-06, 7.56907938e-06, 2.25718523e-06,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.38617003e-07,\n",
       "       4.83508299e-07, 2.72629708e-06, 7.86972789e-06, 1.96004772e-05,\n",
       "       6.23562698e-05, 1.42157438e-04, 2.12552050e-04, 4.92027991e-04,\n",
       "       5.84834267e-04, 8.36896445e-04, 1.01774621e-03, 2.41472807e-03,\n",
       "       2.02151879e-03, 1.41064844e-03, 1.61667823e-03, 6.26825859e-04,\n",
       "       2.34063455e-04, 9.98339131e-05, 6.39842882e-05, 3.81580077e-05,\n",
       "       6.29324481e-06, 4.15238677e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       5.38501826e-06, 1.71319473e-05, 3.00584674e-05, 9.29955921e-05,\n",
       "       2.21380175e-04, 3.41108817e-04, 7.21467690e-04, 1.34999063e-03,\n",
       "       1.79946756e-03, 2.06340745e-03, 1.83154621e-03, 2.01310129e-03,\n",
       "       1.39366596e-03, 1.29414689e-03, 6.57546808e-04, 5.33744774e-04,\n",
       "       3.09226836e-04, 2.07373760e-04, 1.34228796e-04, 6.81099778e-05,\n",
       "       3.17371424e-05, 6.99859062e-06, 5.88165127e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.57603741e-06,\n",
       "       2.21466388e-05, 6.10651586e-05, 1.19825550e-04, 2.61505682e-04,\n",
       "       6.01380025e-04, 1.05480445e-03, 2.22984108e-03, 3.11033912e-03,\n",
       "       3.52415673e-03, 4.34023765e-03, 4.91676921e-03, 7.37246261e-03,\n",
       "       4.56208120e-03, 3.91842553e-03, 1.98031993e-03, 1.55309031e-03,\n",
       "       1.09517545e-03, 6.68950546e-04, 5.78965123e-04, 3.99064526e-04,\n",
       "       7.81806545e-05, 2.28104499e-05, 4.16560534e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 8.25706001e-06, 2.03185524e-06,\n",
       "       4.87874806e-05, 1.14311076e-04, 2.37766187e-04, 4.39345775e-04,\n",
       "       8.68439964e-04, 1.39682305e-03, 2.22741684e-03, 2.80155499e-03,\n",
       "       2.45526279e-03, 3.37129365e-03, 3.81977846e-03, 5.28858647e-03,\n",
       "       3.20202957e-03, 3.00495506e-03, 2.33709383e-03, 1.22979598e-03,\n",
       "       1.43272828e-03, 1.18564114e-03, 1.04283478e-03, 9.31328773e-04,\n",
       "       2.52983832e-04, 1.09338073e-04, 1.51558212e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.66603160e-06, 6.42546168e-06, 1.18836454e-05,\n",
       "       5.09371946e-05, 2.02915221e-04, 3.90324116e-04, 6.56733084e-04,\n",
       "       1.34370936e-03, 1.70190066e-03, 2.51120390e-03, 2.08811370e-03,\n",
       "       2.69312618e-03, 4.10717522e-03, 5.58025153e-03, 5.39742169e-03,\n",
       "       4.24065673e-03, 2.91708380e-03, 2.07057933e-03, 2.36567068e-03,\n",
       "       1.80224733e-03, 1.69192684e-03, 1.13360126e-03, 1.37467160e-03,\n",
       "       6.27201812e-04, 1.48730581e-04, 1.62616942e-05, 1.98061140e-06,\n",
       "       0.00000000e+00, 2.19864576e-06, 3.04013116e-06, 3.35107174e-05,\n",
       "       6.90706025e-05, 1.78015211e-04, 5.37372695e-04, 6.43594566e-04,\n",
       "       1.04008770e-03, 1.42038723e-03, 2.65376267e-03, 3.17285879e-03,\n",
       "       3.61556126e-03, 3.93927422e-03, 4.98577049e-03, 5.01180873e-03,\n",
       "       4.28668755e-03, 2.85629549e-03, 3.38474024e-03, 3.14216215e-03,\n",
       "       1.59935660e-03, 1.50518588e-03, 1.01005315e-03, 1.07518672e-03,\n",
       "       6.50771159e-04, 2.15824499e-04, 1.79643768e-05, 6.54424036e-07,\n",
       "       0.00000000e+00, 2.13724689e-06, 5.83850121e-07, 2.51173579e-05,\n",
       "       9.69388657e-05, 2.36106169e-04, 3.80739828e-04, 6.45620153e-04,\n",
       "       1.21558280e-03, 3.29577603e-03, 3.53901801e-03, 5.05059503e-03,\n",
       "       3.23532334e-03, 3.71999885e-03, 3.46576714e-03, 4.51503347e-03,\n",
       "       3.61646653e-03, 4.11015619e-03, 3.12084015e-03, 3.84412852e-03,\n",
       "       3.24349417e-03, 1.16276524e-03, 7.99823587e-04, 6.54822053e-04,\n",
       "       3.66994374e-04, 9.22964792e-05, 1.67192367e-05, 1.26323629e-06,\n",
       "       0.00000000e+00, 2.26567088e-06, 1.24769407e-05, 3.07907115e-05,\n",
       "       1.05076678e-04, 1.93434506e-04, 4.14158581e-04, 8.40772184e-04,\n",
       "       1.56298822e-03, 3.55616164e-03, 5.43444895e-03, 5.47535949e-03,\n",
       "       3.16020516e-03, 2.75302305e-03, 3.28420279e-03, 3.86597868e-03,\n",
       "       3.71713583e-03, 4.42775034e-03, 3.46027958e-03, 3.51717722e-03,\n",
       "       2.54299998e-03, 1.85250022e-03, 1.18740081e-03, 4.99008381e-04,\n",
       "       1.82962355e-04, 6.94933668e-05, 1.57455794e-05, 2.25400490e-06,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.50547469e-06, 3.78207895e-05,\n",
       "       7.46519212e-05, 2.36341518e-04, 4.58186672e-04, 1.33575537e-03,\n",
       "       2.08168688e-03, 4.57380414e-03, 6.29462716e-03, 5.72690648e-03,\n",
       "       2.88164641e-03, 2.80664774e-03, 5.34011926e-03, 4.48215296e-03,\n",
       "       3.88801097e-03, 3.39185101e-03, 4.61616067e-03, 3.58632996e-03,\n",
       "       1.90328171e-03, 2.38053245e-03, 1.17651970e-03, 8.27087541e-04,\n",
       "       1.20909505e-04, 2.33784353e-05, 1.34466432e-05, 1.09973076e-06,\n",
       "       0.00000000e+00, 6.52226138e-07, 5.13046757e-06, 2.47065913e-05,\n",
       "       9.82862214e-05, 2.96702677e-04, 9.75943804e-04, 1.39007729e-03,\n",
       "       2.05839149e-03, 4.39276541e-03, 5.87521143e-03, 5.70625926e-03,\n",
       "       4.95930704e-03, 3.90625894e-03, 7.66824268e-03, 5.71139012e-03,\n",
       "       3.67620601e-03, 4.54875537e-03, 4.42753919e-03, 2.15389291e-03,\n",
       "       1.40681757e-03, 1.69250345e-03, 2.14830107e-03, 1.14743820e-03,\n",
       "       1.43324555e-04, 2.32881931e-05, 9.06845220e-06, 1.27678652e-06,\n",
       "       0.00000000e+00, 1.28832589e-06, 1.78133421e-06, 1.70110796e-05,\n",
       "       7.08050501e-05, 3.27429676e-04, 9.23489147e-04, 2.30442502e-03,\n",
       "       2.82915472e-03, 5.73039717e-03, 5.45934558e-03, 6.57443261e-03,\n",
       "       4.19964086e-03, 5.46356298e-03, 1.13653194e-02, 4.64060603e-03,\n",
       "       5.18065013e-03, 5.73554421e-03, 3.52046309e-03, 1.62993467e-03,\n",
       "       1.44602816e-03, 1.41946369e-03, 2.77629913e-03, 1.32242834e-03,\n",
       "       1.35612897e-04, 2.82672386e-05, 9.75047182e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.18142242e-06, 1.90431832e-05,\n",
       "       7.43960619e-05, 4.36751575e-04, 7.54973069e-04, 2.67682197e-03,\n",
       "       5.13103517e-03, 4.12870479e-03, 4.78634688e-03, 5.19601554e-03,\n",
       "       4.37473130e-03, 8.91449927e-03, 7.36843863e-03, 3.33993189e-03,\n",
       "       3.63770719e-03, 7.61737411e-03, 4.18523726e-03, 1.49627252e-03,\n",
       "       1.15962421e-03, 1.00049162e-03, 1.29077661e-03, 4.68936721e-04,\n",
       "       1.44647943e-04, 4.23922925e-05, 3.81447210e-06, 4.41084628e-07,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.48127803e-06, 1.46126185e-05,\n",
       "       6.75843369e-05, 3.97273344e-04, 1.48895611e-03, 2.81424221e-03,\n",
       "       4.57819584e-03, 5.24091805e-03, 3.77925966e-03, 3.81668067e-03,\n",
       "       4.63779997e-03, 7.35266257e-03, 6.30795002e-03, 3.39597928e-03,\n",
       "       3.64756283e-03, 6.01666916e-03, 2.31107326e-03, 2.04535162e-03,\n",
       "       1.19504257e-03, 1.76223119e-03, 1.24710431e-03, 4.07909014e-04,\n",
       "       1.41370953e-04, 4.05552439e-05, 4.36653998e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 6.39042998e-07, 2.93700453e-05,\n",
       "       9.04425592e-05, 6.17512984e-04, 2.17632552e-03, 2.72664657e-03,\n",
       "       3.41059532e-03, 4.29295100e-03, 4.32988598e-03, 4.19216960e-03,\n",
       "       7.44068106e-03, 7.82635915e-03, 6.44995118e-03, 3.00985503e-03,\n",
       "       2.73873070e-03, 3.58727535e-03, 2.82176922e-03, 1.63065015e-03,\n",
       "       1.73613362e-03, 1.07656577e-03, 6.86935730e-04, 3.83879167e-04,\n",
       "       2.14521970e-04, 4.91287862e-05, 1.51536895e-05, 3.96647675e-06,\n",
       "       0.00000000e+00, 0.00000000e+00, 5.61038976e-06, 4.56144614e-05,\n",
       "       1.11367648e-04, 7.11730420e-04, 1.16121611e-03, 2.34259371e-03,\n",
       "       2.81998680e-03, 3.33729464e-03, 5.08340568e-03, 5.62612977e-03,\n",
       "       6.70266811e-03, 7.12425513e-03, 4.29101143e-03, 2.98249130e-03,\n",
       "       2.20935696e-03, 2.38473787e-03, 1.87097509e-03, 1.75805440e-03,\n",
       "       1.60855773e-03, 9.08981565e-04, 5.86529097e-04, 2.92041824e-04,\n",
       "       1.40711788e-04, 4.36279476e-05, 8.50605227e-06, 5.34354445e-06,\n",
       "       0.00000000e+00, 0.00000000e+00, 9.58908834e-06, 7.32885445e-05,\n",
       "       1.35651911e-04, 3.94903413e-04, 1.60807549e-03, 1.61810543e-03,\n",
       "       2.55341399e-03, 4.97938356e-03, 6.14326753e-03, 4.93672450e-03,\n",
       "       4.47436205e-03, 4.06016914e-03, 2.53855663e-03, 1.78513150e-03,\n",
       "       1.46712813e-03, 1.80741673e-03, 2.87175300e-03, 2.52340242e-03,\n",
       "       1.38758584e-03, 1.07208120e-03, 5.88312385e-04, 3.45354121e-04,\n",
       "       1.91567645e-04, 7.75347997e-05, 7.39111661e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 8.13009084e-06, 5.86868079e-05,\n",
       "       1.51051002e-04, 6.55838800e-04, 1.43959316e-03, 3.61963931e-03,\n",
       "       3.99982642e-03, 4.87442873e-03, 5.30480963e-03, 5.96457832e-03,\n",
       "       3.95174528e-03, 2.63761474e-03, 2.00429753e-03, 1.49704107e-03,\n",
       "       1.27832490e-03, 3.82064339e-03, 1.86517685e-03, 2.87917838e-03,\n",
       "       1.79673895e-03, 9.41482871e-04, 9.19149825e-04, 4.83816975e-04,\n",
       "       1.52919092e-04, 2.35012471e-05, 5.06807033e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.18746072e-05, 1.06998594e-04,\n",
       "       1.84448842e-04, 8.50983154e-04, 1.33082879e-03, 3.87696718e-03,\n",
       "       4.45889497e-03, 4.81897917e-03, 3.30736459e-03, 3.99215989e-03,\n",
       "       2.97355823e-03, 2.37218416e-03, 2.03261478e-03, 1.66594646e-03,\n",
       "       1.41834669e-03, 1.59294605e-03, 1.94751421e-03, 2.16964366e-03,\n",
       "       1.35697737e-03, 1.27582373e-03, 7.14983064e-04, 2.24504134e-04,\n",
       "       1.19317726e-04, 2.48906928e-05, 2.88635927e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 5.83526220e-06, 5.83120223e-05,\n",
       "       1.91072665e-04, 4.71754691e-04, 1.32553307e-03, 2.93827825e-03,\n",
       "       3.97177103e-03, 4.30266748e-03, 3.11504824e-03, 1.71646692e-03,\n",
       "       1.50016120e-03, 1.56995933e-03, 1.43711421e-03, 1.40685795e-03,\n",
       "       1.24081920e-03, 1.38749295e-03, 1.18398611e-03, 1.00512173e-03,\n",
       "       1.00303413e-03, 4.55125506e-04, 3.02217170e-04, 1.64514956e-04,\n",
       "       5.42713274e-05, 1.22448981e-05, 6.44904216e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.56424227e-06, 3.19597991e-05,\n",
       "       1.06757157e-04, 2.43763784e-04, 6.84777795e-04, 1.99439914e-03,\n",
       "       2.85855962e-03, 2.67772452e-03, 3.08603830e-03, 1.91514147e-03,\n",
       "       1.75034837e-03, 1.95641809e-03, 2.19145723e-03, 1.66502537e-03,\n",
       "       1.53704058e-03, 1.10009660e-03, 8.00958659e-04, 8.85745351e-04,\n",
       "       5.98812795e-04, 2.94542913e-04, 1.60947267e-04, 6.94180711e-05,\n",
       "       1.72084998e-05, 9.17565355e-06, 3.00214057e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 6.52607928e-07, 1.70897418e-05,\n",
       "       5.75920826e-05, 1.31919953e-04, 3.03976910e-04, 6.43229951e-04,\n",
       "       1.31926960e-03, 2.23761129e-03, 3.27883884e-03, 4.15820077e-03,\n",
       "       5.63963584e-03, 5.74784901e-03, 4.48928114e-03, 2.10965873e-03,\n",
       "       1.46843167e-03, 9.31617391e-04, 7.72035280e-04, 3.96472133e-04,\n",
       "       2.73139731e-04, 1.35039421e-04, 7.00818351e-05, 3.96344909e-05,\n",
       "       1.15644085e-05, 7.17013965e-06, 6.24834928e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.94940204e-06,\n",
       "       3.02152495e-05, 1.10948119e-04, 2.94915967e-04, 3.46406987e-04,\n",
       "       5.53210797e-04, 9.75164706e-04, 1.16006964e-03, 1.12823426e-03,\n",
       "       1.35180256e-03, 1.11643339e-03, 9.91470662e-04, 9.19505105e-04,\n",
       "       6.74397103e-04, 5.11711522e-04, 4.07743049e-04, 2.02701571e-04,\n",
       "       1.40779421e-04, 7.32639990e-05, 4.84443091e-05, 2.79035529e-05,\n",
       "       2.87698583e-06, 1.25720724e-06, 1.80086756e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.55385308e-06,\n",
       "       1.20248889e-05, 4.19419630e-05, 1.09037912e-04, 2.57367824e-04,\n",
       "       4.61524469e-04, 7.70486964e-04, 8.77962785e-04, 1.50966729e-03,\n",
       "       8.66711125e-04, 6.08633596e-04, 6.82457999e-04, 5.75298140e-04,\n",
       "       5.35688418e-04, 4.12036974e-04, 4.32758765e-04, 2.33168000e-04,\n",
       "       9.43622076e-05, 3.94851644e-05, 2.66727335e-05, 9.59632867e-06,\n",
       "       6.49566740e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.25862504e-06, 9.09366325e-06, 1.06138174e-05, 2.37211294e-05,\n",
       "       3.86920295e-05, 1.18478444e-04, 6.93109291e-05, 1.95753926e-04,\n",
       "       4.75227888e-04, 1.71739872e-04, 1.19120993e-04, 1.83259810e-04,\n",
       "       8.64268784e-05, 9.99300640e-05, 7.09977098e-05, 4.16325754e-05,\n",
       "       1.04883578e-05, 1.09334400e-05, 3.44655682e-06, 2.27641690e-06,\n",
       "       2.10628863e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       9.92406153e-07, 1.87099144e-06, 0.00000000e+00, 4.78447241e-06,\n",
       "       2.03861683e-06, 3.23608396e-06, 7.51013626e-06, 1.07292514e-05,\n",
       "       9.72417787e-07, 8.74714325e-06, 5.10443307e-07, 4.96193356e-07,\n",
       "       1.19897862e-06, 1.30195117e-06, 0.00000000e+00, 6.46962103e-07,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel377 0.011365319400624263\n",
      "pixel404 0.008914499267599685\n",
      "pixel460 0.007826359153579862\n",
      "pixel349 0.007668242675031955\n",
      "pixel408 0.007617374107823399\n",
      "pixel459 0.007440681060753752\n",
      "pixel154 0.0073724626050181985\n",
      "pixel405 0.007368438626747965\n",
      "pixel432 0.0073526625664400505\n",
      "pixel488 0.007124255128665397\n",
      "pixel487 0.00670266810751228\n",
      "pixel374 0.006574432608726678\n",
      "pixel461 0.006449951179303208\n",
      "pixel433 0.006307950015501611\n",
      "pixel317 0.006294627164517706\n",
      "pixel513 0.006143267528901684\n",
      "pixel436 0.00601666916154536\n",
      "pixel542 0.005964578318726067\n",
      "pixel345 0.005875211426240128\n",
      "pixel656 0.005747849007097036\n",
      "pixel380 0.00573554421183375\n",
      "pixel372 0.005730397173686793\n",
      "pixel318 0.005726906476294365\n",
      "pixel350 0.0057113901171710335\n",
      "pixel346 0.005706259262246644\n",
      "pixel655 0.005639635842353083\n",
      "pixel486 0.005626129773372487\n",
      "pixel209 0.005580251527795898\n",
      "pixel290 0.005475359493461381\n",
      "pixel376 0.005463562980888557\n",
      "pixel373 0.005459345584504399\n",
      "pixel289 0.005434448947141393\n",
      "pixel210 0.005397421689932275\n",
      "pixel321 0.005340119261566701\n",
      "pixel541 0.0053048096298647495\n",
      "pixel182 0.005288586474902303\n",
      "pixel428 0.005240918045721122\n",
      "pixel402 0.0051960155371672005\n",
      "pixel379 0.005180650127039338\n",
      "pixel399 0.005131035165116992\n",
      "pixel485 0.005083405683859777\n",
      "pixel262 0.005050595027997277\n",
      "pixel238 0.005011808731136748\n",
      "pixel237 0.0049857704925498495\n",
      "pixel512 0.004979383564646174\n",
      "pixel347 0.0049593070357843525\n",
      "pixel514 0.004936724500563993\n",
      "pixel153 0.004916769214508756\n",
      "pixel540 0.00487442872795279\n",
      "pixel568 0.004818979173427215\n",
      "pixel401 0.0047863468837500475\n",
      "pixel378 0.004640606025655531\n",
      "pixel431 0.004637799969490578\n",
      "pixel325 0.004616160667629001\n",
      "pixel427 0.00457819584452978\n",
      "pixel316 0.0045738041386987486\n",
      "pixel155 0.004562081195681978\n",
      "pixel352 0.004548755365123048\n",
      "pixel266 0.004515033472275393\n",
      "pixel657 0.00448928114131793\n",
      "pixel322 0.00448215295983534\n",
      "pixel515 0.004474362054938139\n",
      "pixel567 0.004458894974170905\n",
      "pixel296 0.0044277503392222235\n",
      "pixel353 0.004427539188945368\n",
      "pixel344 0.004392765408253596\n",
      "pixel403 0.0043747313011106214\n",
      "pixel152 0.0043402376453404974\n",
      "pixel457 0.004329885978518661\n",
      "pixel596 0.004302667480589906\n",
      "pixel456 0.0042929509999642445\n",
      "pixel489 0.004291011428144301\n",
      "pixel239 0.004286687554865027\n",
      "pixel211 0.004240656726429677\n",
      "pixel375 0.004199640864865642\n",
      "pixel458 0.0041921695958132285\n",
      "pixel409 0.00418523726355217\n",
      "pixel654 0.004158200771763034\n",
      "pixel400 0.004128704786786936\n",
      "pixel268 0.004110156189548425\n",
      "pixel208 0.004107175220914429\n",
      "pixel516 0.004060169139781027\n",
      "pixel539 0.003999826422111253\n",
      "pixel570 0.003992159885117442\n",
      "pixel595 0.003971771032695687\n",
      "pixel543 0.00395174528228016\n",
      "pixel236 0.003939274215047747\n",
      "pixel156 0.003918425525622979\n",
      "pixel348 0.003906258941368325\n",
      "pixel323 0.0038880109681808804\n",
      "pixel566 0.003876967180384984\n",
      "pixel294 0.0038659786786205304\n",
      "pixel270 0.003844128517930579\n",
      "pixel548 0.0038206433946335384\n",
      "pixel181 0.0038197784577241184\n",
      "pixel430 0.0038166806710233534\n",
      "pixel429 0.0037792596592685856\n",
      "pixel264 0.0037199988504748164\n",
      "pixel295 0.0037171358316543312\n",
      "pixel351 0.0036762060107093\n",
      "pixel435 0.0036475628318044955\n",
      "pixel407 0.0036377071888310467\n",
      "pixel538 0.0036196393096287315\n",
      "pixel267 0.003616466530685561\n",
      "pixel235 0.0036155612554456323\n",
      "pixel464 0.0035872753540224034\n",
      "pixel326 0.003586329962938859\n",
      "pixel288 0.0035561616360464355\n",
      "pixel261 0.0035390180070961823\n",
      "pixel151 0.003524156733770028\n",
      "pixel381 0.0035204630872982005\n",
      "pixel298 0.003517177215426516\n",
      "pixel265 0.003465767144755062\n",
      "pixel297 0.003460279576746265\n",
      "pixel455 0.0034105953223335416\n",
      "pixel434 0.003395979283712108\n",
      "pixel324 0.003391851011331844\n",
      "pixel241 0.0033847402354873772\n",
      "pixel180 0.0033712936500857205\n",
      "pixel406 0.00333993189377868\n",
      "pixel484 0.003337294641266666\n",
      "pixel569 0.003307364590635241\n",
      "pixel260 0.003295776033480266\n",
      "pixel293 0.00328420278729582\n",
      "pixel653 0.003278838838952528\n",
      "pixel271 0.0032434941691302593\n",
      "pixel263 0.003235323338567012\n",
      "pixel183 0.0032020295745017555\n",
      "pixel234 0.0031728587883579694\n",
      "pixel291 0.003160205159267055\n",
      "pixel242 0.003142162149461978\n",
      "pixel269 0.003120840148543832\n",
      "pixel597 0.0031150482386641098\n",
      "pixel150 0.003110339122627341\n",
      "pixel625 0.0030860382990473985\n",
      "pixel462 0.0030098550325296704\n",
      "pixel184 0.003004955057077881\n",
      "pixel490 0.0029824913007872236\n",
      "pixel571 0.0029735582266833087\n",
      "pixel594 0.002938278249293147\n",
      "pixel212 0.002917083801684349\n",
      "pixel319 0.0028816464086358273\n",
      "pixel550 0.002879178380015747\n",
      "pixel521 0.002871752995639227\n",
      "pixel623 0.0028585596174223373\n",
      "pixel240 0.0028562954877933725\n",
      "pixel371 0.002829154715973689\n",
      "pixel465 0.0028217692210469616\n",
      "pixel483 0.0028199867956251057\n",
      "pixel426 0.0028142422062786402\n",
      "pixel320 0.0028066477429784364\n",
      "pixel178 0.002801554988740915\n",
      "pixel385 0.002776299128271899\n",
      "pixel292 0.0027530230465957345\n",
      "pixel463 0.0027387307040902037\n",
      "pixel454 0.0027266465668346414\n",
      "pixel207 0.0026931261793803\n",
      "pixel624 0.002677724523034466\n",
      "pixel398 0.00267682197250198\n",
      "pixel233 0.002653762674463285\n",
      "pixel544 0.002637614742010618\n",
      "pixel511 0.002553413992468326\n",
      "pixel299 0.0025429999826107135\n",
      "pixel517 0.0025385566294451323\n",
      "pixel522 0.0025234024239892067\n",
      "pixel205 0.0025112039031530875\n",
      "pixel179 0.00245526279292862\n",
      "pixel98 0.0024147280694490343\n",
      "pixel492 0.0023847378674639137\n",
      "pixel328 0.0023805324490658187\n",
      "pixel572 0.002372184164319949\n",
      "pixel214 0.002365670676140212\n",
      "pixel482 0.0023425937143408703\n",
      "pixel185 0.002337093833527264\n",
      "pixel437 0.0023110732621147104\n",
      "pixel370 0.002304425017083212\n",
      "pixel652 0.0022376112915018704\n",
      "pixel149 0.0022298410800479455\n",
      "pixel177 0.0022274168400089975\n",
      "pixel491 0.0022093569608292447\n",
      "pixel629 0.0021914572285408425\n",
      "pixel453 0.00217632552260911\n",
      "pixel578 0.002169643658902962\n",
      "pixel354 0.002153892913677406\n",
      "pixel357 0.0021483010651894546\n",
      "pixel658 0.0021096587328963555\n",
      "pixel206 0.002088113697456868\n",
      "pixel315 0.0020816868771612682\n",
      "pixel213 0.0020705793338723615\n",
      "pixel124 0.0020634074547944956\n",
      "pixel343 0.0020583914906173177\n",
      "pixel438 0.002045351615382834\n",
      "pixel573 0.0020326147780614775\n",
      "pixel99 0.0020215187928817597\n",
      "pixel126 0.002013101291532271\n",
      "pixel545 0.0020042975297052974\n",
      "pixel622 0.0019943991367780438\n",
      "pixel157 0.0019803199302071608\n",
      "pixel628 0.001956418092300302\n",
      "pixel577 0.0019475142142973976\n",
      "pixel626 0.0019151414704895212\n",
      "pixel327 0.0019032817110337503\n",
      "pixel493 0.0018709750932629219\n",
      "pixel549 0.0018651768536273703\n",
      "pixel300 0.0018525002221387872\n",
      "pixel125 0.0018315462116821524\n",
      "pixel520 0.0018074167290833012\n",
      "pixel215 0.0018022473327621966\n",
      "pixel123 0.0017994675563856955\n",
      "pixel551 0.0017967389475392061\n",
      "pixel518 0.0017851314998526178\n",
      "pixel440 0.0017622311925157353\n",
      "pixel494 0.0017580544015700736\n",
      "pixel627 0.001750348369165688\n",
      "pixel467 0.0017361336170522972\n",
      "pixel598 0.0017164669210057576\n",
      "pixel204 0.0017019006639177453\n",
      "pixel356 0.001692503446316147\n",
      "pixel216 0.00169192683737672\n",
      "pixel574 0.001665946462704985\n",
      "pixel630 0.0016650253734471147\n",
      "pixel466 0.0016306501450655281\n",
      "pixel382 0.0016299346720996507\n",
      "pixel510 0.0016181054280007456\n",
      "pixel101 0.0016166782264125312\n",
      "pixel495 0.0016085577321384593\n",
      "pixel509 0.0016080754938771699\n",
      "pixel243 0.0015993565957061417\n",
      "pixel576 0.0015929460476701196\n",
      "pixel600 0.001569959333804663\n",
      "pixel287 0.0015629882161145602\n",
      "pixel158 0.0015530903135495828\n",
      "pixel631 0.0015370405820741926\n",
      "pixel710 0.001509667290659485\n",
      "pixel244 0.0015051858833626131\n",
      "pixel599 0.0015001611957529725\n",
      "pixel546 0.0014970410650009761\n",
      "pixel410 0.0014962725155756565\n",
      "pixel425 0.0014889561055756865\n",
      "pixel659 0.001468431669937875\n",
      "pixel519 0.0014671281307255587\n",
      "pixel383 0.0014460281608233538\n",
      "pixel537 0.0014395931603068044\n",
      "pixel601 0.0014371142115708077\n",
      "pixel187 0.0014327282820815663\n",
      "pixel232 0.0014203872310872396\n",
      "pixel384 0.0014194636943723284\n",
      "pixel575 0.001418346688706228\n",
      "pixel100 0.001410648436971066\n",
      "pixel602 0.0014068579463806575\n",
      "pixel355 0.0014068175681844978\n",
      "pixel176 0.0013968230486328399\n",
      "pixel127 0.0013936659607306058\n",
      "pixel342 0.0013900772921624318\n",
      "pixel523 0.0013875858440056921\n",
      "pixel604 0.0013874929516895886\n",
      "pixel218 0.0013746716039968812\n",
      "pixel579 0.0013569773741016675\n",
      "pixel683 0.001351802563879901\n",
      "pixel122 0.0013499906277998513\n",
      "pixel203 0.001343709359436465\n",
      "pixel314 0.0013357553683513682\n",
      "pixel565 0.0013308287879938536\n",
      "pixel593 0.0013255330725716143\n",
      "pixel386 0.001322428343373619\n",
      "pixel651 0.0013192695989676431\n",
      "pixel128 0.001294146887970843\n",
      "pixel413 0.0012907766087375675\n",
      "pixel547 0.0012783248990308096\n",
      "pixel580 0.001275823725052325\n",
      "pixel441 0.0012471043064887055\n",
      "pixel603 0.0012408192033108501\n",
      "pixel186 0.0012297959788317913\n",
      "pixel259 0.0012155828042882783\n",
      "pixel439 0.001195042573841246\n",
      "pixel301 0.001187400814936635\n",
      "pixel188 0.0011856411413762524\n",
      "pixel605 0.0011839861102644783\n",
      "pixel329 0.0011765197028143998\n",
      "pixel272 0.0011627652400762116\n",
      "pixel481 0.0011612161076229378\n",
      "pixel681 0.0011600696424405165\n",
      "pixel411 0.0011596242082637554\n",
      "pixel358 0.0011474381986835164\n",
      "pixel217 0.0011336012576908605\n",
      "pixel682 0.001128234256239262\n",
      "pixel684 0.0011164333920130707\n",
      "pixel632 0.0011000966038368985\n",
      "pixel159 0.0010951754537305003\n",
      "pixel468 0.0010765657661023882\n",
      "pixel246 0.0010751867157798955\n",
      "pixel524 0.0010720811994453037\n",
      "pixel148 0.0010548044535684151\n",
      "pixel189 0.0010428347789369608\n",
      "pixel231 0.001040087703070963\n",
      "pixel97 0.001017746208406689\n",
      "pixel245 0.0010100531465922383\n",
      "pixel606 0.0010051217308957854\n",
      "pixel607 0.0010030341318406349\n",
      "pixel412 0.001000491617271584\n",
      "pixel685 0.0009914706619322958\n",
      "pixel341 0.0009759438036187735\n",
      "pixel680 0.0009751647057860511\n",
      "pixel552 0.0009414828707831646\n",
      "pixel660 0.0009316173913951804\n",
      "pixel190 0.0009313287734332338\n",
      "pixel369 0.0009234891468451457\n",
      "pixel686 0.0009195051045922958\n",
      "pixel553 0.0009191498253958783\n",
      "pixel496 0.0009089815649617576\n",
      "pixel634 0.0008857453507592443\n",
      "pixel709 0.0008779627851481482\n",
      "pixel175 0.0008684399637307616\n",
      "pixel711 0.0008667111247622661\n",
      "pixel564 0.0008509831536134258\n",
      "pixel286 0.0008407721840246103\n",
      "pixel96 0.0008368964448583738\n",
      "pixel330 0.0008270875406719571\n",
      "pixel633 0.000800958659267398\n",
      "pixel273 0.000799823586741015\n",
      "pixel661 0.0007720352804985978\n",
      "pixel708 0.0007704869643410487\n",
      "pixel397 0.0007549730692390532\n",
      "pixel121 0.0007214676903775303\n",
      "pixel581 0.0007149830636165671\n",
      "pixel480 0.000711730420377811\n",
      "pixel469 0.0006869357304004352\n",
      "pixel621 0.0006847777945473115\n",
      "pixel713 0.0006824579987481177\n",
      "pixel687 0.0006743971026942093\n",
      "pixel160 0.0006689505457215578\n",
      "pixel129 0.00065754680794485\n",
      "pixel202 0.0006567330838918937\n",
      "pixel536 0.0006558388003416248\n",
      "pixel274 0.0006548220534786603\n",
      "pixel247 0.0006507711588260063\n",
      "pixel258 0.0006456201525939781\n",
      "pixel230 0.0006435945657039558\n",
      "pixel650 0.0006432299507687224\n",
      "pixel219 0.0006272018123524941\n",
      "pixel102 0.0006268258585340919\n",
      "pixel452 0.0006175129836370431\n",
      "pixel712 0.0006086335960417315\n",
      "pixel147 0.0006013800254444038\n",
      "pixel635 0.000598812794988813\n",
      "pixel525 0.0005883123845289762\n",
      "pixel497 0.0005865290967583455\n",
      "pixel95 0.0005848342665207787\n",
      "pixel161 0.0005789651226567706\n",
      "pixel714 0.0005752981403244588\n",
      "pixel679 0.0005532107973944431\n",
      "pixel229 0.0005373726952406818\n",
      "pixel715 0.0005356884182895073\n",
      "pixel130 0.0005337447737396705\n",
      "pixel688 0.0005117115218570199\n",
      "pixel302 0.0004990083813471869\n",
      "pixel94 0.0004920279905318111\n",
      "pixel554 0.00048381697537783376\n",
      "pixel739 0.00047522788807244045\n",
      "pixel592 0.0004717546905636033\n",
      "pixel414 0.0004689367212037253\n",
      "pixel707 0.00046152446942958087\n",
      "pixel313 0.00045818667213688165\n",
      "pixel608 0.000455125505873672\n",
      "pixel174 0.00043934577483465716\n",
      "pixel396 0.0004367515751985359\n",
      "pixel717 0.00043275876466574917\n",
      "pixel285 0.0004141585805010602\n",
      "pixel716 0.00041203697361336713\n",
      "pixel442 0.00040790901448102795\n",
      "pixel689 0.00040774304917545555\n",
      "pixel162 0.00039906452571070427\n",
      "pixel424 0.00039727334383318107\n",
      "pixel662 0.00039647213314559766\n",
      "pixel508 0.00039490341276907423\n",
      "pixel201 0.00039032411561839837\n",
      "pixel470 0.0003838791668422383\n",
      "pixel257 0.0003807398278006019\n",
      "pixel275 0.00036699437387361587\n",
      "pixel678 0.0003464069865507868\n",
      "pixel526 0.0003453541207541256\n",
      "pixel120 0.0003411088168127645\n",
      "pixel368 0.0003274296764919473\n",
      "pixel131 0.0003092268362852172\n",
      "pixel649 0.00030397690967028383\n",
      "pixel609 0.0003022171701547088\n",
      "pixel340 0.0002967026772047648\n",
      "pixel677 0.000294915966757185\n",
      "pixel636 0.00029454291322954555\n",
      "pixel498 0.0002920418242465242\n",
      "pixel663 0.00027313973144280985\n",
      "pixel146 0.000261505682138887\n",
      "pixel706 0.0002573678243299354\n",
      "pixel191 0.00025298383163436394\n",
      "pixel620 0.00024376378417448953\n",
      "pixel173 0.00023776618724102603\n",
      "pixel312 0.0002363415184909463\n",
      "pixel256 0.00023610616947925092\n",
      "pixel103 0.00023406345500241128\n",
      "pixel718 0.00023316799960221654\n",
      "pixel67 0.00023261448219271817\n",
      "pixel582 0.0002245041335757754\n",
      "pixel119 0.00022138017532371285\n",
      "pixel248 0.00021582449902844304\n",
      "pixel471 0.0002145219701448682\n",
      "pixel93 0.00021255204988755228\n",
      "pixel132 0.00020737376031776579\n",
      "pixel200 0.00020291522088490863\n",
      "pixel690 0.000202701570862226\n",
      "pixel738 0.00019575392614147865\n",
      "pixel284 0.00019343450601604572\n",
      "pixel527 0.00019156764523100395\n",
      "pixel591 0.00019107266544331344\n",
      "pixel72 0.00018718566671826976\n",
      "pixel563 0.00018444884249836784\n",
      "pixel742 0.00018325980981195037\n",
      "pixel303 0.00018296235467137986\n",
      "pixel228 0.00017801521088386553\n",
      "pixel69 0.00017717334793528584\n",
      "pixel740 0.0001717398719919854\n",
      "pixel610 0.00016451495609188924\n",
      "pixel637 0.00016094726661952622\n",
      "pixel70 0.00015765779516083153\n",
      "pixel555 0.0001529190917395152\n",
      "pixel535 0.0001510510018966884\n",
      "pixel220 0.00014873058093102181\n",
      "pixel415 0.00014464794254872012\n",
      "pixel359 0.00014332455547775932\n",
      "pixel92 0.00014215743759771933\n",
      "pixel443 0.0001413709531842483\n",
      "pixel691 0.00014077942117594438\n",
      "pixel499 0.00014071178750285724\n",
      "pixel507 0.00013565191078989802\n",
      "pixel387 0.00013561289713240484\n",
      "pixel664 0.00013503942135292284\n",
      "pixel133 0.00013422879634120984\n",
      "pixel71 0.00013258036900185846\n",
      "pixel648 0.00013191995280910178\n",
      "pixel331 0.00012090950467821148\n",
      "pixel145 0.00011982554956444607\n",
      "pixel583 0.0001193177256886261\n",
      "pixel741 0.00011912099314629594\n",
      "pixel736 0.0001184784444182978\n",
      "pixel73 0.0001162628796295517\n",
      "pixel172 0.00011431107623419015\n",
      "pixel479 0.0001113676479431008\n",
      "pixel676 0.0001109481192989184\n",
      "pixel192 0.00010933807301535422\n",
      "pixel705 0.00010903791213688625\n",
      "pixel562 0.00010699859439755287\n",
      "pixel619 0.00010675715730363292\n",
      "pixel283 0.0001050766775588108\n"
     ]
    }
   ],
   "source": [
    "for feature, imp_score in sorted(zip(digit_dataset.columns, \\\n",
    "                                    rnd_clf.feature_importances_), key=lambda x: x[1], reverse=True):\n",
    "    if(imp_score > 0.0001):\n",
    "        print(feature, imp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_y_pred = rnd_clf.predict(digit_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(digit_y_train, digit_y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9625811123837701\n"
     ]
    }
   ],
   "source": [
    "digit_y_test_pred = rnd_clf.predict(digit_X_test)\n",
    "print(f1_score(digit_y_test, digit_y_test_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How and RandomFoest will solve Overfitting issue in DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <table>  \n",
    "    <tr>\n",
    "        <td> <img src=\"../img/decision_tree_over_fitting.PNG\" alt=\"DecisionTree - Overfitted\" style=\"width: 500px;\"/> </td>\n",
    "        <td> <img src=\"../img/random_forest_fix_overfit.PNG\" alt=\"RandomForest - no Overfitting\" style=\"width: 500px;\"/> </td>\n",
    "    </tr>\n",
    "   </table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "  * Boosting (originally called hypothesis boosting) refers to any Ensemble method that can combine several weak learners into a strong learner. **The general idea of most boosting methods is to train predictors sequentially, each trying to correct its predecessor**. There are many boosting methods available, but by far the most popular are **AdaBoost** (short for Adaptive Boosting) and **Gradient Boosting**. Let’s start with AdaBoost.\n",
    "  \n",
    "### AdaBoost:\n",
    "  * AdaBoost is a popular boosting technique which helps you combine multiple “weak classifiers” (sequentially) into a single “strong classifier”. A weak classifier is simply a classifier that performs poorly, but performs better than random guessing.\n",
    "  * AdaBoost can be applied to any classification algorithm, so it’s really a technique that builds on top of other classifiers.\n",
    "  * You could just train a bunch of weak classifiers on your own and combine the results, so what does AdaBoost do for you? There’s really two things it figures out for you:\n",
    "    * **1) Training set Selection : ** It helps you choose the training set for each new classifier that you train based on the results of the previous classifier.\n",
    "    <img src=\"../img/ada_boosting_example1.png\" alt=\"Bagging\" style=\"width: 500px;\"/> \n",
    "    * **2) Classifier Output Weights : **After each classifier is trained, the classifier’s weight is calculated based on its accuracy. More accurate classifiers are given more weight. A classifier with **50% accuracy is given a weight of zero**, and a classifier with **less than 50% accuracy is given negative weight**.\n",
    "    <img src=\"../img/ada_boosting_example2.png\" alt=\"Pasting\" style=\"width: 700px;\"/>\n",
    "    \n",
    "  #### Step 1:   \n",
    "    * Each instance weight - $w^{(i)}$ is initially set to 1/m. Build model 1.\n",
    "    * First predictor's weight $\\alpha_1$ the classifier is calculated using below formula.\n",
    "    $$ \\alpha_1 = \\eta \\space log \\frac{1 - r_1}{r_1}  $$ \n",
    "      * eta ($\\eta$) is the learning rate hyperparameter.\n",
    "      * $r_1 = \\frac { {\\sum_{i=1}^m w^{(i)}}_{ \\hat{y}_{1}^{(i)} \\not{=} y^{(i)}} } {\\sum_{i=1}^m w^{(i)}}$\n",
    "      \n",
    "  #### Step 2:\n",
    "    * Each instance weight - $w^{(i)}$ is calculated using below formulas.\n",
    "$$ w^{(i)} = w^{(i)} \\space \\space if \\space \\space \\hat{y}_{1}^{(i)} = y^{(i)} $$\n",
    "$$ w^{(i)} = w^{(i)} \\space \\exp{(\\alpha_1)} \\space \\space if \\space \\space \\hat{y}_{1}^{(i)} \\not{=} y^{(i)} $$\n",
    "    \n",
    "    * Once new instance weights are ready, the second classification model is build and predictions are made ($ \\hat{y_2}^{(i)}$). Using these predictions $ r_2$ , and further $ \\alpha_2 $ - the weight for second classifier is calculated.\n",
    "    \n",
    "$$ \\alpha_2 = \\eta \\space log \\frac{1 - r_2}{r_2} $$\n",
    "$$ r_2 = \\frac { {\\sum_{i=1}^m w^{(i)}}_{ \\hat{y}_{2}^{(i)} \\not{=} y^{(i)}} } {\\sum_{i=1}^m w^{(i)}} $$\n",
    "    \n",
    "  #### Step 3, 4, ... : Step 2 is repeated until desired number of predictors are reached or perfect predictor is found.\n",
    "  \n",
    "\n",
    "### Scikit-Learn uses multiclass version of Ada Boost - SAMME (Stagewise Additive Modeling using a Multiclass Exponential loss function). When there are just two classes, SAMME is equivalent to AdaBoost. Moreover, if the predictors can estimate class probabilities, Scikit-Learn can use a variant of SAMME called SAMME.R (R - stants for real), which relies on class probabilities rather than predictions.\n",
    "\n",
    "  * AdaBoosting works with Regression or Classification tasks.\n",
    "  * https://www.youtube.com/watch?v=ix6IvwbVpw0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Following code trains an AdaBoost classifier based on 500 Decision Stumps (A decision stump is a machine learning model consisting of a one-level decision tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                         class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=2,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort='deprecated',\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=0.5, n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(max_depth=2), n_estimators=500,\n",
    "        algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42\n",
    "    )\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = ada_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "  * Just like AdaBoost, Gradient Boosting works by sequentially adding predictors to an ensemble, each one correcting its predecessor. However, **instead of tweaking the instance weights** at every iteration like AdaBoost does, **this method tries to fit the new predictor to the residual errors made by the previous predictor.** The final prediction is going to be the sum of all predictions. \n",
    "  * Gradient Boosting works with Regression or Classification tasks (It works great with Regression tasks).\n",
    "  * When we build Gradient Boosting model using DecisionTreeRegressor we call it as **Gradient Tree Boosting**, or **Gradient Boosted Regression Trees (GBRT)**.\n",
    "  \n",
    "#### Step - 1\n",
    "<img src=\"../img/gredient_boosting_step1.PNG\" alt=\"Gradient Boosting\" style=\"width: 500px;\"/> \n",
    "\n",
    "#### Step - 2\n",
    "<img src=\"../img/gredient_boosting_step2.PNG\" alt=\"Gradient Boosting\" style=\"width: 500px;\"/> \n",
    "\n",
    "#### Step - 3\n",
    "<img src=\"../img/gredient_boosting_step3.PNG\" alt=\"Gradient Boosting\" style=\"width: 500px;\"/> \n",
    "\n",
    "#### Step - 4\n",
    "<img src=\"../img/gredient_boosting_step4.PNG\" alt=\"Gradient Boosting\" style=\"width: 500px;\"/> \n",
    "\n",
    "#### .....\n",
    "\n",
    "#### .....\n",
    "\n",
    "#### Step - n\n",
    "\n",
    "#### Final Step \n",
    "<img src=\"../img/gredient_boosting.PNG\" alt=\"Gradient Boosting\" style=\"width: 500px;\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingRegressor \n",
    "  * A simpler way to train GBRT ensembles is to use Scikit-Learn’s GradientBoostingRegressor class. Much like the RandomForestRegressor class, it has hyperparameters to control the growth of Decision Trees (e.g., max_depth, min_samples_leaf, and so on), as well as hyperparameters to control the ensemble training, such as the number of trees (n_estimators).\n",
    "  * The **learning_rate** hyperparameter scales the contribution of each tree. If you set it to a low value, such as 0.1, you will need more trees in the ensemble to fit the training set, but the predictions will usually generalize better. This is a regularization technique called shrinkage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='ls', max_depth=2,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=42, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbrt_slow = GradientBoostingRegressor(max_depth=2, n_estimators=200, \\\n",
    "                                      learning_rate=0.1, random_state=42)\n",
    "gbrt_slow.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=1.0, loss='ls', max_depth=2,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=42, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=200, \\\n",
    "                                 learning_rate=1.0, random_state=42)\n",
    "gbrt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(regressors, X, y, axes, label=None, style=\"r-\", \\\n",
    "                                                 data_style=\"b.\", data_label=None):\n",
    "    x1 = np.linspace(axes[0], axes[1], 500)\n",
    "    y_pred = sum(regressor.predict(x1.reshape(-1, 1)) for regressor in regressors)\n",
    "    plt.plot(X[:, 0], y, data_style, label=data_label)\n",
    "    plt.plot(x1, y_pred, style, linewidth=2, label=label)\n",
    "    if label or data_label:\n",
    "        plt.legend(loc=\"upper center\", fontsize=16)\n",
    "    plt.axis(axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_predictions([gbrt], X, y, axes=[-0.5, 0.5, -0.1, 0.8], label=\"Ensemble predictions\")\n",
    "plt.title(\"learning_rate={}, n_estimators={}\".\\\n",
    "                            format(gbrt.learning_rate, gbrt.n_estimators), fontsize=14)\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_predictions([gbrt_slow], X, y, axes=[-0.5, 0.5, -0.1, 0.8])\n",
    "plt.title(\"learning_rate={}, n_estimators={}\".format(gbrt_slow.learning_rate, \\\n",
    "                                                    gbrt_slow.n_estimators), fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
