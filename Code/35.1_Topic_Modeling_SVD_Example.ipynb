{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling using Sigular Value Decomposition\n",
    "  * Singular Value Decomposion is a Linear Algebraic concept used in may areas such as machine learning (principal component analysis, Latent Semantic Analysis, Recommender Systems and word embedding), data mining and bioinformatics.\n",
    "  * The technique decomposes given matrix into there matrices, let's look at programmer's perspective of the technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a small dataset and create Document-Term matrix.\n",
    "  * Note: Need to build Term-Document matrix For Query Retrieval in IR task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"I enjoy Machine Learning\", \"I like NLP\", \"I like deep learning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(1, 1))\n",
    "X = cv.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X is the Document-Term Matrix, \"DOCUMENTS\" - are the \"rows\";  \"TOKENS\" - are the \"columns\" of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 1],\n",
       "       [1, 0, 1, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deep', 'enjoy', 'learning', 'like', 'machine', 'nlp']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enjoy': 1, 'machine': 4, 'learning': 2, 'like': 3, 'nlp': 5, 'deep': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notation \n",
    "  * \"*\" - for Matrix multiplication\n",
    "  * V.T - to denote Transpose of matrix V\n",
    "  \n",
    "#### Now SVD will decompose rectangular matrix X into there matrices. Namely U, S and V.T (V transpose)\n",
    "  * U - the left Eigen vector (orthogonal) matrix, the vectors extracts \"Document-to-Document similarity\". \n",
    "  * V - the right Eigen vector (orthogonal) matrix, the vectors extract \"Strength of Two Different Words Occurring in one Document\" (may or may-not be co-occurrence)\n",
    "  * S - the Eigen Values (diagonal) matrix, explains variance ratio.\n",
    "#### Before we understand how U, V, S extract relation strengh or explain variance ratio. Let's understand on how to decompose X.\n",
    "  * To decomposing any matrix, we should use Eigen Vectors, Eigen Values decomposition.\n",
    "  * A matrix is **eligible** to apply Eigen decomposition only when it is a **square and symmetric matrix*.\n",
    "  * We can get a SQUARE, SYMMETRIC matrix by multiplying \"X.T with X\" or \"X with X.T\", we can decompose these (np.dot(X.T,X) and np.dot(X,X.T) and get U, S, V matrixes.\n",
    "#### Why to multiply \"X.T with X\" or \"X with X.T\"?, Why to decompose \"X.T with X\" or \"X with X.T\"?\n",
    "  * **Suppose that X is decomposed as U S V.T**\n",
    "    * **i.e., X = U * S * V.T**\n",
    "    \n",
    "  * Now let's see what is X.T multiplied by X\n",
    "    * X.T * X = (U * S * V.T).T * (U * S * V.T)\n",
    "    * &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        = (V * S.T * U.T) * (U * S * V)\n",
    "    * &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        = V * S.T * (U.T * U) * S * V)\n",
    "    * &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        = V * S.T * (I) * S * V    # as U is an orthogonal matrix U.T * U = I\n",
    "    * &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        = V * (S.T * S) * V\n",
    "    * &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        = V * S^2 * V      # as S is diagnoal matrix S.T * S is S-square    \n",
    "  * We got V * S^2 * V, when we multiply X.T with X, where X is in decomposed form (U * S * V.T), **Hence, when we decompose X.T * X, we get values of matrix V and S^2**\n",
    "  \n",
    "  * Now let's see what is X multiplied by X.T\n",
    "    * X * X.T = (U * S * V.T) * (U * S * V.T).T\n",
    "    * &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        = (U * S * V) * (V.T * S.T * U)\n",
    "    * &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        = (U * S * (V * V.T) * S.T * U)\n",
    "    * &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        = U * S * (I) * S.T * V    # as U is an orthogonal matrix U.T * U = I\n",
    "    * &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        = U * (S.T * S) * U\n",
    "    * &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        = U * S^2 * U      # as S is diagnoal matrix S * S.T is S-square    \n",
    "  * We got U * S^2 * U, when we multiply X.T with X, where X is in decomposed form (U * S * V.T), **Hence, when we decompose X * X.T, we get values of matrix U and S^2**\n",
    "  \n",
    "  * **Bottom line: To find U, S and V, we need to find Eigen Decoposition of X.T * X and X * X.T**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X.T * X is word similarity matrix, the (i, j) position in X.T * X will quantify the overlap of Word-i and Word-j. Number of Documents in which both words i and j occur. (This inference is based out of Document-Term matrix, if it is Tf-IDF, then the inference would be different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deep', 'enjoy', 'learning', 'like', 'machine', 'nlp']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enjoy': 1, 'machine': 4, 'learning': 2, 'like': 3, 'nlp': 5, 'deep': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 1, 0],\n",
       "       [1, 1, 2, 1, 1, 0],\n",
       "       [1, 0, 1, 2, 0, 1],\n",
       "       [0, 1, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X.T, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X * X.T is document similarity matrix, the (i, j) position in X * X.T will quantify the similarity of Document-i and Document-j. This analogy suits best with Tf-IDF scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 1],\n",
       "       [0, 2, 1],\n",
       "       [1, 1, 3]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X, X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  The rows in sigular vector matrix V.T are the topics and values in the row denote strenght of words in the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, Vh = np.linalg.svd(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.35761308  0.28678342  0.6443965   0.51676587  0.28678342  0.15915279]\n",
      " [ 0.20519296 -0.4610644  -0.25587144  0.5749379  -0.4610644   0.36974494]\n",
      " [-0.53995111  0.29965026 -0.24030085  0.13335691  0.29965026  0.67330802]\n",
      " [-0.6580513   0.1075659   0.19856672  0.45948457 -0.30613262 -0.45948457]\n",
      " [-0.20636755 -0.71288399  0.07368819  0.13267936  0.6391958  -0.13267936]\n",
      " [-0.250684   -0.30920965  0.64550737 -0.39482338 -0.33629772  0.39482338]]\n"
     ]
    }
   ],
   "source": [
    "print(Vh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.06082013 1.59842364 1.09456031]\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic- 0 ; scores for features -  [0.35761308 0.28678342 0.6443965  0.51676587 0.28678342 0.15915279]\n",
      "\"featuer\":  deep      \"score\":  0.357613077803957\n",
      "\"featuer\":  enjoy      \"score\":  0.28678342190830464\n",
      "\"featuer\":  learning      \"score\":  0.6443964997122618\n",
      "\"featuer\":  like      \"score\":  0.5167658699398142\n",
      "\"featuer\":  machine      \"score\":  0.28678342190830475\n",
      "\"featuer\":  nlp      \"score\":  0.1591527921358573\n",
      "\n",
      "topic- 1 ; scores for features -  [ 0.20519296 -0.4610644  -0.25587144  0.5749379  -0.4610644   0.36974494]\n",
      "\"featuer\":  deep      \"score\":  0.2051929597703755\n",
      "\"featuer\":  enjoy      \"score\":  -0.461064395430453\n",
      "\"featuer\":  learning      \"score\":  -0.2558714356600775\n",
      "\"featuer\":  like      \"score\":  0.5749378971020997\n",
      "\"featuer\":  machine      \"score\":  -0.46106439543045297\n",
      "\"featuer\":  nlp      \"score\":  0.36974493733172425\n",
      "\n",
      "topic- 2 ; scores for features -  [-0.53995111  0.29965026 -0.24030085  0.13335691  0.29965026  0.67330802]\n",
      "\"featuer\":  deep      \"score\":  -0.5399511064742025\n",
      "\"featuer\":  enjoy      \"score\":  0.29965025746743273\n",
      "\"featuer\":  learning      \"score\":  -0.24030084900676965\n",
      "\"featuer\":  like      \"score\":  0.1333569103038064\n",
      "\"featuer\":  machine      \"score\":  0.29965025746743257\n",
      "\"featuer\":  nlp      \"score\":  0.6733080167780087\n",
      "\n",
      "topic- 3 ; scores for features -  [-0.6580513   0.1075659   0.19856672  0.45948457 -0.30613262 -0.45948457]\n",
      "\"featuer\":  deep      \"score\":  -0.6580512956442615\n",
      "\"featuer\":  enjoy      \"score\":  0.10756589805494082\n",
      "\"featuer\":  learning      \"score\":  0.19856672333377184\n",
      "\"featuer\":  like      \"score\":  0.4594845723104897\n",
      "\"featuer\":  machine      \"score\":  -0.30613262138871294\n",
      "\"featuer\":  nlp      \"score\":  -0.4594845723104896\n",
      "\n",
      "topic- 4 ; scores for features -  [-0.20636755 -0.71288399  0.07368819  0.13267936  0.6391958  -0.13267936]\n",
      "\"featuer\":  deep      \"score\":  -0.20636754873165167\n",
      "\"featuer\":  enjoy      \"score\":  -0.7128839912856285\n",
      "\"featuer\":  learning      \"score\":  0.07368818783020217\n",
      "\"featuer\":  like      \"score\":  0.13267936090144927\n",
      "\"featuer\":  machine      \"score\":  0.6391958034554263\n",
      "\"featuer\":  nlp      \"score\":  -0.13267936090144924\n",
      "\n",
      "topic- 5 ; scores for features -  [-0.250684   -0.30920965  0.64550737 -0.39482338 -0.33629772  0.39482338]\n",
      "\"featuer\":  deep      \"score\":  -0.25068399548622294\n",
      "\"featuer\":  enjoy      \"score\":  -0.3092096504459737\n",
      "\"featuer\":  learning      \"score\":  0.6455073732322905\n",
      "\"featuer\":  like      \"score\":  -0.3948233777460676\n",
      "\"featuer\":  machine      \"score\":  -0.33629772278631687\n",
      "\"featuer\":  nlp      \"score\":  0.3948233777460677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, comp in enumerate(Vh):\n",
    "    print('topic-',i, '; scores for features - ', comp)\n",
    "    z = zip(cv.get_feature_names(), comp)\n",
    "    for a, b in z:\n",
    "        print('\\\"featuer\\\": ',a, '     \\\"score\\\": ', b)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic :  0\n",
      "           learning\n",
      "           like\n",
      "           deep\n",
      "**************************************************\n",
      "topic :  1\n",
      "           like\n",
      "           nlp\n",
      "           deep\n",
      "**************************************************\n",
      "topic :  2\n",
      "           nlp\n",
      "           enjoy\n",
      "           machine\n",
      "**************************************************\n",
      "topic :  3\n",
      "           like\n",
      "           learning\n",
      "           enjoy\n",
      "**************************************************\n",
      "topic :  4\n",
      "           machine\n",
      "           like\n",
      "           learning\n",
      "**************************************************\n",
      "topic :  5\n",
      "           learning\n",
      "           nlp\n",
      "           deep\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "terms = cv.get_feature_names()\n",
    "for i, component in enumerate(Vh):\n",
    "    terms_components = zip(terms, component)\n",
    "    sorted_terms = sorted(terms_components, key=lambda x:x[1], reverse=True)[:3] # take features for topic\n",
    "    print(\"topic : \", i)\n",
    "    for term_socres in sorted_terms:\n",
    "        print(10*\" \", term_socres[0])\n",
    "    print(50*'*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above result may not make sense as the dataset is too small. If we take decent amount data, the results will be promising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cons:\n",
    "  * SVD is a linear decomposition, hence cannot extract non-linear patterns\n",
    "  * SVD computation is very expensive, cannot handle huge volumens of data (Randomized SVD is one of the solutions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
