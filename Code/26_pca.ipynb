{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Dimentionality Reduction - Principal Component Analysis</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * <span style=\"color:red\"> Warning : Reducing dimensionality does lose some information (just like compressing an image to JPEG can degrade its quality), so even though it will speed up training, it may also make your system perform slightly worse. It also makes your pipelines a bit more complex and thus harder to maintain. So you should first try to train your system with the original data before considering using dimensionality reduction if training is too slow. In some cases, however, reducing the dimensionality of the training data may filter out some noise and unnecessary details and thus result in higher performance (but in general it won’t; it will just speed up training). </span>\n",
    "  * Apart from performance improvement, dimentionality reduction is useful in data visualization. Reduce multi-dimentional dataset into two dimentions and plot 2D graph to understand patterns in data (may not give right picture in most of the cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_dataset = pd.read_csv('digit_recognizer_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_X = digit_dataset.iloc[:, 1:]\n",
    "digit_y = digit_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default train_test_split does STRATIFIED split based on label (y-value).\n",
    "from sklearn.model_selection import train_test_split\n",
    "digit_X_train, digit_X_test, digit_y_train, digit_y_test = train_test_split(digit_X, digit_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit = digit_X_train.loc[29814]\n",
    "some_digit_image = some_digit.values.reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   2  39 113 242  22   8   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  58 254 254 254 225 199 185 185 185 185 111  77   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  63 254 253 249 249 249 249 249 249 144 140  97   1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14 233 246  93   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  14 183 254 125   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  44 254 189  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  44 254  48   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  44 254 227 128  58   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   4 103 228 254 247 234 234 148  70   6   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   4  92 128 204 255 254 254 194  55   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   4  54  54 110 223 234   8   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 168 254  10   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 168 254  10   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  18 238 254  10   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 138 254 103   1   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  92 250 214  16   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   7 127 246 192  33   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   1  28   0   0   0  26 186 254 229  62   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   2 139 179 179 179 237 254 209  39   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   7 119 146 192 192  46  14   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(linewidth=115)\n",
    "print(some_digit_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn PCA parameters:\n",
    "  * **n_components:** This hyperparameter can be used to specify **number of components (an Integer)** we want to reduce to OR a float **between 0.0 and 1.0, indicating the ratio of variance you wish to preserve**. \"n_components\" variable on PCA class give access to Principle Components.\n",
    "  <br>\n",
    "  <br>\n",
    "  * **Explained Varience Ratio:** Explained variance ratio of each principal component, available via the  **\"explained_variance_ratio_\"** attribute. It indicates the proportion of the dataset's variance that lies along the axis of each principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 784)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca1 = PCA() \n",
    "pca1.fit_transform(digit_X_train).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here we have 784 Principal Components, one for each feature. \n",
    "* Note that **components_** attribute contains **principal components as horizontal vectors**, so, to access principal component we have to transpose pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 784)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca1.components_[:, :].T.shape ## 784 projection OR 784 principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca1.explained_variance_ratio_.shape ## One explained varience ratio for each feature hence 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09733527, 0.07136311, 0.06136659, 0.05382191, 0.04899597, 0.04289449, 0.03281195, 0.02902706, 0.02763207,\n",
       "       0.02349736, 0.02093499, 0.02038537, 0.01705277, 0.01700235, 0.01589408, 0.01487209, 0.01321232, 0.01290789,\n",
       "       0.01191833, 0.01145691])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca1.explained_variance_ratio_[:20] ## See how the PC's explained varience is reducing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9863398843733187"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca1.explained_variance_ratio_[:300].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To reduce number of columns to 20, n_components=20, the model selects top 20 components with high explained variance ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 20)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca2 = PCA(n_components=20)  ## number of components (an Integer)\n",
    "pca2.fit_transform(digit_X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca2.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If n_components=0.95 (a number between 0 and 1), then model will cumulatively sum explained variance ratio (eigen values) until it reaches n_components. Model will take coresponding \"components of explained variance ratios\" that contributed to n_components percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 154)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca3 = PCA(n_components=0.95)  ## ratio of variance you wish to preserve\n",
    "pca3.fit_transform(digit_X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca3.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to choose Right Number of Dimensions or Principal Components ?\n",
    "  * Approach 1:  Take cumulative sum of explained variance of the principal components, pick a threashold for preserving the origianl dataset variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.73352720e-02, 7.13631066e-02, 6.13665948e-02, 5.38219108e-02, 4.89959684e-02, 4.28944856e-02,\n",
       "       3.28119459e-02, 2.90270593e-02, 2.76320723e-02, 2.34973557e-02, 2.09349882e-02, 2.03853654e-02,\n",
       "       1.70527660e-02, 1.70023500e-02, 1.58940790e-02, 1.48720885e-02, 1.32123166e-02, 1.29078938e-02,\n",
       "       1.19183298e-02, 1.14569135e-02, 1.06825403e-02, 1.01294921e-02, 9.66062958e-03, 9.12784893e-03,\n",
       "       8.89093848e-03, 8.36239152e-03, 8.16249375e-03, 7.75838482e-03, 7.37129751e-03, 6.88466980e-03,\n",
       "       6.57874490e-03, 6.42224585e-03, 5.98360192e-03, 5.91104462e-03, 5.65188998e-03, 5.40661961e-03,\n",
       "       5.10927831e-03, 4.88497657e-03, 4.74762468e-03, 4.69510370e-03, 4.53332049e-03, 4.46109114e-03,\n",
       "       4.21591071e-03, 3.96970875e-03, 3.85576299e-03, 3.76565425e-03, 3.61760871e-03, 3.47378371e-03,\n",
       "       3.38591296e-03, 3.22652776e-03, 3.14520982e-03, 3.09656408e-03, 2.94503624e-03, 2.86967576e-03,\n",
       "       2.81239200e-03, 2.70288320e-03, 2.65169293e-03, 2.56981447e-03, 2.53467240e-03, 2.47346211e-03,\n",
       "       2.41055626e-03, 2.40058453e-03, 2.27795573e-03, 2.21220108e-03, 2.14454628e-03, 2.05339267e-03,\n",
       "       2.02701629e-03, 1.97381474e-03, 1.92998249e-03, 1.90278747e-03, 1.87218234e-03, 1.82304289e-03,\n",
       "       1.77605687e-03, 1.73063712e-03, 1.66329919e-03, 1.62782825e-03, 1.59947852e-03, 1.55621355e-03,\n",
       "       1.47164321e-03, 1.43506165e-03, 1.41153859e-03, 1.39657764e-03, 1.38748198e-03, 1.36223603e-03,\n",
       "       1.32504289e-03, 1.30668285e-03, 1.30187511e-03, 1.24357791e-03, 1.22577639e-03, 1.19420796e-03,\n",
       "       1.15776097e-03, 1.13845752e-03, 1.12869178e-03, 1.10336987e-03, 1.08587791e-03, 1.07688292e-03,\n",
       "       1.04598840e-03, 1.03382972e-03, 1.01074238e-03, 1.00189547e-03, 9.76643507e-04, 9.48850636e-04,\n",
       "       9.46042383e-04, 9.17331492e-04, 9.11927600e-04, 8.89387355e-04, 8.63131783e-04, 8.44118644e-04,\n",
       "       8.38130943e-04, 8.19789010e-04, 7.90870963e-04, 7.83190019e-04, 7.82434033e-04, 7.73259031e-04,\n",
       "       7.59319261e-04, 7.53753574e-04, 7.35717481e-04, 7.26128847e-04, 7.19269086e-04, 7.03476445e-04,\n",
       "       6.96459701e-04, 6.89126441e-04, 6.82915903e-04, 6.65394055e-04, 6.58879033e-04, 6.44251786e-04,\n",
       "       6.39686429e-04, 6.28189177e-04, 6.18239449e-04, 6.07469503e-04, 6.03053521e-04, 5.93201461e-04,\n",
       "       5.86271494e-04, 5.83708983e-04, 5.77156365e-04, 5.72093309e-04, 5.65020300e-04, 5.56911380e-04,\n",
       "       5.36479259e-04, 5.27072066e-04, 5.21662877e-04, 5.11266206e-04, 5.08974809e-04, 5.02561969e-04,\n",
       "       4.96442105e-04, 4.95607382e-04, 4.84601399e-04, 4.79488246e-04, 4.74823185e-04, 4.70365871e-04,\n",
       "       4.64121390e-04, 4.60507348e-04, 4.56525390e-04, 4.50437892e-04, 4.49307953e-04, 4.41566051e-04,\n",
       "       4.37859935e-04, 4.24755921e-04, 4.22823756e-04, 4.17854872e-04, 4.15606377e-04, 4.08448700e-04,\n",
       "       4.02184177e-04, 3.96681952e-04, 3.94776459e-04, 3.89687385e-04, 3.82648069e-04, 3.78341053e-04,\n",
       "       3.77277149e-04, 3.73732019e-04, 3.66186925e-04, 3.62552437e-04, 3.60584226e-04, 3.58018402e-04,\n",
       "       3.54513111e-04, 3.51968855e-04, 3.44837450e-04, 3.43191900e-04, 3.42719610e-04, 3.38362992e-04,\n",
       "       3.34642725e-04, 3.30450301e-04, 3.25559866e-04, 3.23419476e-04, 3.21628586e-04, 3.20012250e-04,\n",
       "       3.17362754e-04, 3.17028957e-04, 3.11745970e-04, 3.11028687e-04, 3.06825967e-04, 3.05450888e-04,\n",
       "       3.00044645e-04, 2.96576345e-04, 2.95377256e-04, 2.93880265e-04, 2.91332120e-04, 2.89406043e-04,\n",
       "       2.85450803e-04, 2.83720074e-04, 2.80007571e-04, 2.77971855e-04, 2.73996247e-04, 2.71477367e-04,\n",
       "       2.68412665e-04, 2.66587886e-04, 2.63331374e-04, 2.62561716e-04, 2.62448106e-04, 2.59033456e-04,\n",
       "       2.57495991e-04, 2.56376395e-04, 2.54312116e-04, 2.51553084e-04, 2.50922691e-04, 2.49649508e-04,\n",
       "       2.48832182e-04, 2.45423906e-04, 2.43624969e-04, 2.40959499e-04, 2.39637910e-04, 2.39041288e-04,\n",
       "       2.38294007e-04, 2.36534384e-04, 2.32259669e-04, 2.30407528e-04, 2.28386340e-04, 2.27155543e-04,\n",
       "       2.26922100e-04, 2.24642858e-04, 2.20318478e-04, 2.18423917e-04, 2.18148971e-04, 2.16259796e-04,\n",
       "       2.15539400e-04, 2.14070011e-04, 2.12428300e-04, 2.10890101e-04, 2.08986463e-04, 2.04637366e-04,\n",
       "       2.03138973e-04, 2.02789505e-04, 2.01349827e-04, 1.98989847e-04, 1.97721389e-04, 1.96888105e-04,\n",
       "       1.96083581e-04, 1.94625749e-04, 1.93061052e-04, 1.91809898e-04, 1.89941961e-04, 1.87832674e-04,\n",
       "       1.86848898e-04, 1.85410060e-04, 1.84860664e-04, 1.84012320e-04, 1.82631414e-04, 1.81886756e-04,\n",
       "       1.80534681e-04, 1.79202100e-04, 1.77585650e-04, 1.76264613e-04, 1.75408258e-04, 1.74877500e-04,\n",
       "       1.72661930e-04, 1.72462236e-04, 1.71158877e-04, 1.69580217e-04, 1.68856952e-04, 1.67277405e-04,\n",
       "       1.66126418e-04, 1.64965934e-04, 1.63897281e-04, 1.62152948e-04, 1.61741141e-04, 1.60946613e-04,\n",
       "       1.60516426e-04, 1.58713455e-04, 1.58451948e-04, 1.57127273e-04, 1.55636361e-04, 1.53694505e-04,\n",
       "       1.52770760e-04, 1.51294224e-04, 1.50381140e-04, 1.49797427e-04, 1.48916971e-04, 1.47743283e-04,\n",
       "       1.47399625e-04, 1.45810787e-04, 1.44166407e-04, 1.43208957e-04, 1.42552940e-04, 1.41762356e-04,\n",
       "       1.40993269e-04, 1.40300116e-04, 1.38649185e-04, 1.37110658e-04, 1.36307569e-04, 1.35723695e-04,\n",
       "       1.34677287e-04, 1.34076648e-04, 1.33719955e-04, 1.31804697e-04, 1.31172434e-04, 1.29605401e-04,\n",
       "       1.28343173e-04, 1.27550491e-04, 1.26912958e-04, 1.26140325e-04, 1.25681158e-04, 1.24986135e-04,\n",
       "       1.23253993e-04, 1.22246979e-04, 1.21998166e-04, 1.21233484e-04, 1.20638201e-04, 1.19796885e-04,\n",
       "       1.19137093e-04, 1.17551348e-04, 1.17147462e-04, 1.15790297e-04, 1.14627155e-04, 1.14153927e-04,\n",
       "       1.13363204e-04, 1.12998611e-04, 1.11924488e-04, 1.10883187e-04, 1.09994596e-04, 1.09241439e-04,\n",
       "       1.08643798e-04, 1.08307327e-04, 1.07939729e-04, 1.06702655e-04, 1.05959504e-04, 1.05456231e-04,\n",
       "       1.04578866e-04, 1.03823859e-04, 1.03443172e-04, 1.02407498e-04, 1.01663838e-04, 1.00397017e-04,\n",
       "       9.96645706e-05, 9.92818200e-05, 9.86120097e-05, 9.72134641e-05, 9.66379406e-05, 9.60152026e-05,\n",
       "       9.46045249e-05, 9.41945700e-05, 9.31764530e-05, 9.20865452e-05, 9.16939763e-05, 9.07801082e-05,\n",
       "       8.99475696e-05, 8.98193420e-05, 8.94268668e-05, 8.89568315e-05, 8.86581606e-05, 8.74352011e-05,\n",
       "       8.66792675e-05, 8.62096902e-05, 8.45868513e-05, 8.44496226e-05, 8.40660900e-05, 8.36084485e-05,\n",
       "       8.23857895e-05, 8.21275951e-05, 8.17639196e-05, 8.04664294e-05, 7.95453603e-05, 7.89177447e-05,\n",
       "       7.88864085e-05, 7.77893524e-05, 7.74546443e-05, 7.68794032e-05, 7.57384271e-05, 7.49030133e-05,\n",
       "       7.46707857e-05, 7.32373433e-05, 7.28664198e-05, 7.24162074e-05, 7.21160311e-05, 7.17458306e-05,\n",
       "       7.12732541e-05, 6.96841509e-05, 6.90017219e-05, 6.79739519e-05, 6.75265714e-05, 6.69078589e-05,\n",
       "       6.62303761e-05, 6.56703392e-05, 6.50074995e-05, 6.39100365e-05, 6.29405501e-05, 6.23420826e-05,\n",
       "       6.12806144e-05, 6.03603777e-05, 5.99493087e-05, 5.91459439e-05, 5.88049367e-05, 5.81261758e-05,\n",
       "       5.75638638e-05, 5.71403104e-05, 5.63138973e-05, 5.61438228e-05, 5.51928186e-05, 5.42975844e-05,\n",
       "       5.38768774e-05, 5.36543770e-05, 5.30236270e-05, 5.26777507e-05, 5.24106429e-05, 5.14238146e-05,\n",
       "       5.10935723e-05, 5.08209865e-05, 5.03613514e-05, 4.95837461e-05, 4.85054012e-05, 4.80388717e-05,\n",
       "       4.70816475e-05, 4.69375317e-05, 4.63749761e-05, 4.61130370e-05, 4.54604668e-05, 4.46733596e-05,\n",
       "       4.34583461e-05, 4.27185827e-05, 4.25007924e-05, 4.22596694e-05, 4.19423506e-05, 4.11790297e-05,\n",
       "       4.05744107e-05, 4.02743787e-05, 3.95903300e-05, 3.85585399e-05, 3.81672236e-05, 3.79276686e-05,\n",
       "       3.73096603e-05, 3.69702013e-05, 3.63963277e-05, 3.60178953e-05, 3.53734992e-05, 3.52573216e-05,\n",
       "       3.48086068e-05, 3.41210607e-05, 3.36871836e-05, 3.35348277e-05, 3.30505105e-05, 3.27939639e-05,\n",
       "       3.21722826e-05, 3.16592487e-05, 3.14189455e-05, 3.09433023e-05, 3.02818109e-05, 3.00574013e-05,\n",
       "       2.95588217e-05, 2.94705713e-05, 2.90333885e-05, 2.83809837e-05, 2.82787160e-05, 2.78068464e-05,\n",
       "       2.69542553e-05, 2.64511837e-05, 2.58880057e-05, 2.56822882e-05, 2.50037891e-05, 2.48642732e-05,\n",
       "       2.44168985e-05, 2.42855798e-05, 2.41133563e-05, 2.38436715e-05, 2.35919281e-05, 2.28385210e-05,\n",
       "       2.24703509e-05, 2.20006734e-05, 2.18417697e-05, 2.13556382e-05, 2.10987813e-05, 2.10083230e-05,\n",
       "       2.07207228e-05, 2.05180725e-05, 2.01797743e-05, 1.99276840e-05, 1.98316481e-05, 1.93485106e-05,\n",
       "       1.90852684e-05, 1.89214777e-05, 1.87158567e-05, 1.86161027e-05, 1.79676055e-05, 1.74444037e-05,\n",
       "       1.72747062e-05, 1.72174030e-05, 1.60774627e-05, 1.57978261e-05, 1.54875749e-05, 1.54683477e-05,\n",
       "       1.53299963e-05, 1.51313603e-05, 1.48904517e-05, 1.47922293e-05, 1.47293944e-05, 1.42566684e-05,\n",
       "       1.40421933e-05, 1.40342947e-05, 1.37930089e-05, 1.36674126e-05, 1.34808209e-05, 1.32575820e-05,\n",
       "       1.31678149e-05, 1.26920738e-05, 1.25075351e-05, 1.22809361e-05, 1.21068177e-05, 1.18592257e-05,\n",
       "       1.17092928e-05, 1.14730827e-05, 1.14511740e-05, 1.09446805e-05, 1.08528257e-05, 1.07256412e-05,\n",
       "       1.05506929e-05, 1.04125953e-05, 1.03495582e-05, 1.02429047e-05, 9.72405194e-06, 9.49961823e-06,\n",
       "       9.38129702e-06, 9.18881740e-06, 9.08172315e-06, 8.97661766e-06, 8.83060477e-06, 8.42230023e-06,\n",
       "       8.36882748e-06, 8.16723088e-06, 8.02981657e-06, 7.94482112e-06, 7.78457182e-06, 7.66291291e-06,\n",
       "       7.56853000e-06, 7.26369060e-06, 7.16825907e-06, 7.09090457e-06, 6.94333092e-06, 6.88962844e-06,\n",
       "       6.60215539e-06, 6.54035985e-06, 6.36204251e-06, 6.22180216e-06, 6.04800358e-06, 5.82709613e-06,\n",
       "       5.63058863e-06, 5.56559711e-06, 5.45183089e-06, 5.28676516e-06, 5.16877558e-06, 5.11635225e-06,\n",
       "       5.04485882e-06, 4.91683474e-06, 4.84937384e-06, 4.81214317e-06, 4.78964814e-06, 4.57871335e-06,\n",
       "       4.36218394e-06, 4.32571022e-06, 4.25608648e-06, 4.15796632e-06, 4.04079664e-06, 3.95549967e-06,\n",
       "       3.88735412e-06, 3.64008346e-06, 3.56524869e-06, 3.52498431e-06, 3.45921803e-06, 3.29210631e-06,\n",
       "       3.19607577e-06, 3.17179969e-06, 3.11224937e-06, 3.02554598e-06, 2.93960798e-06, 2.87025319e-06,\n",
       "       2.75099782e-06, 2.63254646e-06, 2.58825034e-06, 2.58390349e-06, 2.53247344e-06, 2.41460064e-06,\n",
       "       2.36295176e-06, 2.30119623e-06, 2.25790407e-06, 2.22517914e-06, 2.21102556e-06, 2.14767277e-06,\n",
       "       2.13258425e-06, 1.99672111e-06, 1.91315719e-06, 1.77412744e-06, 1.72148314e-06, 1.69023307e-06,\n",
       "       1.68553763e-06, 1.66776453e-06, 1.63725540e-06, 1.63115244e-06, 1.58016575e-06, 1.56484084e-06,\n",
       "       1.52280434e-06, 1.41294092e-06, 1.36677073e-06, 1.31404700e-06, 1.24970617e-06, 1.21921868e-06,\n",
       "       1.21073454e-06, 1.17874325e-06, 1.14106827e-06, 1.00927043e-06, 9.84839928e-07, 9.52999707e-07,\n",
       "       9.48620863e-07, 8.94443683e-07, 8.89683625e-07, 8.84782178e-07, 8.67882447e-07, 8.27992084e-07,\n",
       "       8.00070047e-07, 7.98531954e-07, 7.77112161e-07, 7.54519005e-07, 7.28098394e-07, 6.92502355e-07,\n",
       "       6.88015111e-07, 6.79005191e-07, 6.22356643e-07, 6.18196771e-07, 6.06579436e-07, 5.90817407e-07,\n",
       "       5.39509328e-07, 4.93604266e-07, 4.82278217e-07, 4.70408566e-07, 4.38977527e-07, 3.94198123e-07,\n",
       "       3.65020319e-07, 3.32500098e-07, 3.23932425e-07, 3.18353876e-07, 3.09993623e-07, 3.07323238e-07,\n",
       "       2.94975629e-07, 2.78468827e-07, 2.64723246e-07, 2.37220611e-07, 2.34131664e-07, 2.32937783e-07,\n",
       "       2.32538980e-07, 2.30518616e-07, 2.22013498e-07, 2.16811673e-07, 1.90907508e-07, 1.85259357e-07,\n",
       "       1.84395017e-07, 1.23420322e-07, 1.09073829e-07, 1.08787430e-07, 1.08657107e-07, 1.01211414e-07,\n",
       "       9.17519225e-08, 8.37344438e-08, 7.49584108e-08, 6.53900564e-08, 5.75379113e-08, 5.33367685e-08,\n",
       "       5.16950350e-08, 4.50002158e-08, 4.43192315e-08, 2.90626867e-08, 2.75295922e-08, 2.42843518e-08,\n",
       "       2.16998243e-08, 2.13129897e-08, 1.90365364e-08, 1.79817440e-08, 1.21969994e-08, 1.16051447e-08,\n",
       "       8.93241693e-09, 8.84272388e-09, 8.06753621e-09, 6.50410485e-09, 4.15573832e-09, 3.89564476e-09,\n",
       "       2.50821116e-09, 1.04103572e-09, 3.24627255e-10, 1.31579339e-10, 4.47006744e-12, 3.04444742e-13,\n",
       "       1.92038544e-32, 3.97631390e-33, 3.34853281e-33, 2.93644558e-33, 1.88883677e-33, 1.62735055e-33,\n",
       "       1.46643639e-33, 1.34444781e-33, 6.65874357e-34, 5.40489622e-34, 5.38532271e-34, 5.25352768e-34,\n",
       "       5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34,\n",
       "       5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34,\n",
       "       5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34,\n",
       "       5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34,\n",
       "       5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34,\n",
       "       5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34,\n",
       "       5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34,\n",
       "       5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34,\n",
       "       5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34,\n",
       "       5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34,\n",
       "       5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34,\n",
       "       5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.25352768e-34, 5.22717870e-34,\n",
       "       2.10124311e-34, 2.00697605e-34, 1.77178198e-34, 3.16966454e-35])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca1.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09790498, 0.16961305, 0.23129417, 0.28509142, 0.33408105, 0.37686498, 0.40969494, 0.43884009, 0.46623828,\n",
       "       0.48957922, 0.51049776, 0.5311464 , 0.54814808, 0.56514447, 0.58097221, 0.59580131, 0.60893549, 0.6218129 ,\n",
       "       0.63364525, 0.64512549, 0.65583805, 0.66589694, 0.67561814, 0.68478623, 0.69361131, 0.70201502, 0.71016315,\n",
       "       0.71796791, 0.72537501, 0.7322294 , 0.73881345, 0.74523339, 0.75123253, 0.75711308, 0.76274807, 0.76816062,\n",
       "       0.77322276, 0.77807654, 0.78281684, 0.78748131, 0.79202696, 0.79644709, 0.80061704, 0.8045789 , 0.80841863,\n",
       "       0.81215359, 0.81577905, 0.81925403, 0.82262074, 0.8258334 , 0.82899834, 0.83208564, 0.83504187, 0.83789791,\n",
       "       0.8407014 , 0.84338577, 0.84603914, 0.84859784, 0.85112728, 0.8535867 , 0.85598491, 0.85837132, 0.86065697,\n",
       "       0.86287312, 0.86502185, 0.8670881 , 0.86911431, 0.87106297, 0.87300516, 0.87488037, 0.87675211, 0.87856132,\n",
       "       0.88032419, 0.88203078, 0.88368566, 0.88531438, 0.88692463, 0.88846056, 0.88993083, 0.89135847, 0.89277145,\n",
       "       0.89417442, 0.89555191, 0.89689881, 0.89821437, 0.8995204 , 0.90082152, 0.90206513, 0.90328972, 0.90448465,\n",
       "       0.90563848, 0.90677981, 0.90789682, 0.90899882, 0.91008228, 0.91115104, 0.91218973, 0.9132217 , 0.91423128,\n",
       "       0.91523168, 0.9162033 , 0.91714506, 0.91807675, 0.91899004, 0.91989478, 0.92077552, 0.92163894, 0.9224822 ,\n",
       "       0.92331658, 0.92413093, 0.92491977, 0.92570164, 0.92648272, 0.92725145, 0.92800704, 0.92875796, 0.929491  ,\n",
       "       0.93021409, 0.93092888, 0.93163105, 0.93232506, 0.93300952, 0.93369138, 0.93435801, 0.93501106, 0.93565594,\n",
       "       0.93629161, 0.93691284, 0.93752795, 0.93813625, 0.93873659, 0.93933002, 0.93991901, 0.94050113, 0.94107636,\n",
       "       0.94164077, 0.94220364, 0.94275183, 0.94328204, 0.94380743, 0.94432983, 0.94483929, 0.94534538, 0.94584477,\n",
       "       0.94633795, 0.94682609, 0.94730668, 0.94778327, 0.9482571 , 0.94872789, 0.94919189, 0.94965231, 0.95010527,\n",
       "       0.95055709, 0.95100527, 0.95144619, 0.95188147, 0.95230593, 0.95272697, 0.95314021, 0.95355213, 0.95396024,\n",
       "       0.95435949, 0.95475407, 0.9551449 , 0.95553348, 0.95591446, 0.95629194, 0.95666925, 0.95704262, 0.95740888,\n",
       "       0.95777114, 0.95813235, 0.95848941, 0.9588412 , 0.95919053, 0.95953577, 0.95987734, 0.96021663, 0.96055495,\n",
       "       0.96088802, 0.96121535, 0.96154005, 0.96186347, 0.96218558, 0.96250522, 0.96282267, 0.96313984, 0.96345171,\n",
       "       0.96375938, 0.96406549, 0.96437017, 0.96466972, 0.96496801, 0.96526261, 0.96555506, 0.96584605, 0.96613551,\n",
       "       0.96642162, 0.96670339, 0.96698318, 0.96725905, 0.96753345, 0.96780501, 0.96807291, 0.96833977, 0.96860225,\n",
       "       0.96886379, 0.96912424, 0.96938328, 0.96963999, 0.9698951 , 0.97014889, 0.97040198, 0.97065258, 0.97090037,\n",
       "       0.9711475 , 0.97139381, 0.97163754, 0.97187788, 0.97211721, 0.97235628, 0.97259264, 0.97282789, 0.97305916,\n",
       "       0.97328928, 0.9735176 , 0.97374485, 0.97396914, 0.97419241, 0.97441267, 0.97463147, 0.97484902, 0.97506406,\n",
       "       0.97527873, 0.97549108, 0.97570226, 0.97591244, 0.97612133, 0.97632567, 0.9765294 , 0.97673304, 0.97693425,\n",
       "       0.97713326, 0.97733059, 0.97752693, 0.97772189, 0.9779149 , 0.97810742, 0.97829899, 0.97848832, 0.9786767 ,\n",
       "       0.97886365, 0.97904894, 0.97923381, 0.97941804, 0.97960139, 0.97978322, 0.97996372, 0.98014325, 0.98032033,\n",
       "       0.98049575, 0.9806704 , 0.98084352, 0.98101561, 0.98118664, 0.98135655, 0.98152586, 0.98169379, 0.98186017,\n",
       "       0.98202512, 0.98218925, 0.98235305, 0.98251617, 0.98267856, 0.98283987, 0.98299941, 0.98315821, 0.98331538,\n",
       "       0.98347159, 0.98362711, 0.98378094, 0.98393459, 0.98408624, 0.9842367 , 0.98438632, 0.98453578, 0.98468389,\n",
       "       0.98483043, 0.98497522, 0.98511901, 0.98526222, 0.98540444, 0.98554654, 0.98568688, 0.98582623, 0.98596473,\n",
       "       0.98610214, 0.98623776, 0.98637301, 0.986508  , 0.98664142, 0.98677321, 0.98690459, 0.98703507, 0.9871648 ,\n",
       "       0.98729349, 0.98742127, 0.98754781, 0.98767397, 0.98779921, 0.9879237 , 0.98804729, 0.98817007, 0.98829183,\n",
       "       0.98841321, 0.98853319, 0.98865249, 0.98877122, 0.98888942, 0.98900545, 0.98912101, 0.98923598, 0.98935015,\n",
       "       0.98946332, 0.98957606, 0.98968796, 0.98979862, 0.98990823, 0.99001704, 0.99012527, 0.99023306, 0.99033997,\n",
       "       0.99044631, 0.99055251, 0.99065823, 0.99076227, 0.990866  , 0.99096841, 0.99107035, 0.99117103, 0.99127126,\n",
       "       0.99137111, 0.99146972, 0.9915681 , 0.9916649 , 0.99176095, 0.99185665, 0.99195113, 0.992045  , 0.99213827,\n",
       "       0.99223109, 0.99232265, 0.99241388, 0.99250421, 0.99259433, 0.99268352, 0.99277234, 0.99286008, 0.99294769,\n",
       "       0.99303441, 0.99311979, 0.99320505, 0.99328938, 0.99337353, 0.99345748, 0.99354019, 0.99362193, 0.99370305,\n",
       "       0.99378343, 0.99386319, 0.99394162, 0.99401996, 0.99409756, 0.99417445, 0.99425074, 0.99432623, 0.99440089,\n",
       "       0.99447497, 0.99454814, 0.994621  , 0.99469339, 0.99476506, 0.9948365 , 0.99490764, 0.99497716, 0.9950459 ,\n",
       "       0.99511417, 0.99518195, 0.99524896, 0.99531575, 0.99538136, 0.99544595, 0.99550923, 0.99557225, 0.99563465,\n",
       "       0.99569568, 0.99575608, 0.99581582, 0.99587495, 0.99593323, 0.99599126, 0.99604904, 0.99610645, 0.99616299,\n",
       "       0.99621871, 0.99627421, 0.99632855, 0.99638253, 0.99643606, 0.9964892 , 0.99654211, 0.99659424, 0.99664554,\n",
       "       0.99669641, 0.99674665, 0.99679668, 0.99684553, 0.9968943 , 0.99694245, 0.99698933, 0.99703576, 0.99708189,\n",
       "       0.99712756, 0.99717271, 0.99721684, 0.99726044, 0.99730328, 0.99734578, 0.99738792, 0.99742964, 0.99747072,\n",
       "       0.99751103, 0.99755119, 0.99759106, 0.99762948, 0.99766744, 0.99770505, 0.99774231, 0.99777938, 0.99781561,\n",
       "       0.99785173, 0.99788674, 0.99792156, 0.9979558 , 0.99799   , 0.99802399, 0.9980572 , 0.99809027, 0.99812304,\n",
       "       0.998155  , 0.99818654, 0.99821792, 0.99824859, 0.99827889, 0.99830873, 0.99833843, 0.99836762, 0.99839646,\n",
       "       0.99842506, 0.99845306, 0.99848038, 0.99850742, 0.99853406, 0.99855976, 0.99858535, 0.99861059, 0.99863554,\n",
       "       0.99866003, 0.99868446, 0.99870841, 0.99873221, 0.99875569, 0.998779  , 0.99880198, 0.99882422, 0.99884591,\n",
       "       0.99886723, 0.99888833, 0.99890938, 0.99893017, 0.99895066, 0.99897084, 0.99899089, 0.9990104 , 0.99902966,\n",
       "       0.99904866, 0.99906713, 0.99908552, 0.9991036 , 0.99912149, 0.99913916, 0.99915664, 0.99917394, 0.9991899 ,\n",
       "       0.9992056 , 0.99922121, 0.99923652, 0.99925151, 0.99926647, 0.99928135, 0.99929587, 0.9993101 , 0.99932421,\n",
       "       0.99933795, 0.99935156, 0.99936511, 0.99937844, 0.99939157, 0.99940441, 0.99941721, 0.99942994, 0.99944232,\n",
       "       0.99945457, 0.99946638, 0.99947812, 0.9994897 , 0.99950122, 0.9995127 , 0.99952386, 0.99953501, 0.99954601,\n",
       "       0.99955671, 0.99956731, 0.99957749, 0.9995876 , 0.99959739, 0.99960681, 0.99961612, 0.99962539, 0.99963438,\n",
       "       0.9996433 , 0.99965197, 0.99966035, 0.99966866, 0.99967662, 0.99968445, 0.9996922 , 0.99969986, 0.99970744,\n",
       "       0.99971492, 0.99972221, 0.99972941, 0.99973642, 0.99974325, 0.99974998, 0.99975634, 0.99976267, 0.99976885,\n",
       "       0.99977494, 0.99978101, 0.9997869 , 0.99979257, 0.99979817, 0.99980358, 0.99980888, 0.99981408, 0.99981921,\n",
       "       0.99982427, 0.99982924, 0.99983415, 0.99983888, 0.99984359, 0.99984823, 0.99985271, 0.99985704, 0.99986123,\n",
       "       0.99986537, 0.99986942, 0.99987333, 0.99987714, 0.99988094, 0.99988466, 0.99988828, 0.99989176, 0.99989516,\n",
       "       0.9998984 , 0.99990156, 0.99990463, 0.99990767, 0.99991063, 0.99991353, 0.99991627, 0.99991897, 0.99992157,\n",
       "       0.99992411, 0.99992661, 0.99992904, 0.99993139, 0.99993372, 0.99993604, 0.99993831, 0.99994046, 0.99994257,\n",
       "       0.99994464, 0.99994667, 0.99994866, 0.99995062, 0.99995244, 0.99995423, 0.99995598, 0.99995764, 0.99995928,\n",
       "       0.99996088, 0.99996242, 0.99996395, 0.99996534, 0.99996668, 0.99996796, 0.99996919, 0.99997042, 0.99997161,\n",
       "       0.99997278, 0.99997392, 0.99997504, 0.99997609, 0.99997709, 0.99997806, 0.99997899, 0.9999799 , 0.99998078,\n",
       "       0.99998165, 0.99998249, 0.99998332, 0.99998415, 0.99998496, 0.99998562, 0.99998627, 0.9999869 , 0.99998752,\n",
       "       0.99998812, 0.99998869, 0.99998925, 0.9999898 , 0.99999034, 0.99999085, 0.99999136, 0.99999184, 0.9999923 ,\n",
       "       0.99999273, 0.99999316, 0.99999355, 0.99999394, 0.99999431, 0.99999467, 0.99999502, 0.99999537, 0.99999571,\n",
       "       0.99999603, 0.99999635, 0.99999663, 0.99999688, 0.99999713, 0.99999737, 0.9999976 , 0.99999783, 0.99999803,\n",
       "       0.99999824, 0.99999844, 0.99999865, 0.99999882, 0.99999893, 0.99999902, 0.99999911, 0.99999919, 0.99999927,\n",
       "       0.99999935, 0.99999942, 0.99999949, 0.99999956, 0.99999962, 0.99999967, 0.99999972, 0.99999976, 0.99999979,\n",
       "       0.99999981, 0.99999983, 0.99999985, 0.99999987, 0.99999989, 0.9999999 , 0.99999992, 0.99999993, 0.99999995,\n",
       "       0.99999996, 0.99999996, 0.99999997, 0.99999998, 0.99999999, 0.99999999, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_cumsum = np.cumsum(pca1.explained_variance_ratio_)\n",
    "arr_cumsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(arr_cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_cumsum[699:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components for 99% preserverd vairance :  330\n"
     ]
    }
   ],
   "source": [
    "num_components = np.argmax(arr_cumsum >= 0.99) + 1\n",
    "print(\"Number of components for 99% preserverd vairance : \", num_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now use this \"num_components\"  as a paramenter in PCA(n_components=num_components), get data with dimentionality reduced from 784 to 330."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 330)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_99 = PCA(n_components=num_components)\n",
    "digit_X_train_99 = pca_99.fit_transform(digit_X_train)\n",
    "digit_X_train_99.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * Approach 2:  Plot the explained variance (cumulative) as a function of the number of dimensions. There will usually be an elbow in the curve, where the explained variance stops growing fast. We can take the number of dimentions at this elbow as the best explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_lbls = np.arange(len(arr_cumsum))\n",
    "plt.plot(x_lbls, arr_cumsum, \"b-\", linewidth=2)\n",
    "plt.xlabel(\"Number of PCs\", fontsize=14) \n",
    "plt.ylabel(\"Cumulative Explained Variance\", fontsize=14)   \n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 400)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_dim_400 = PCA(n_components=400)\n",
    "digit_X_train_dim_400 = pca_dim_400.fit_transform(digit_X_train)\n",
    "digit_X_train_dim_400.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 400)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_dim_400.components_[:, :].T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decompress (Inverse Transform) the reduced dataset back to 784 dimensions: \n",
    "  * We can decompress the reduced dataset back to 784 dimensions by applying the inverse transformation of the PCA projection. **This reconstructed data won't give back the original data,** since the projection lost a bit of information (within the 5% variance that was dropped), but it will likely be quite close to the original data. The mean squared distance between the original data and the reconstructed data (compressed and then decompressed) is called the **\"Reconstruction Error\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 784)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_X_train_reconstructed = pca_dim_400.inverse_transform(digit_X_train_dim_400)\n",
    "digit_X_train_reconstructed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([21063, 11633, 22280,  6174, 22531, 26810, 40841,  8629, 23049,\n",
       "            25651,\n",
       "            ...\n",
       "               59, 32227,  9635, 33027, 22844, 36410, 32810, 39245, 29475,\n",
       "            38375],\n",
       "           dtype='int64', length=33600)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_X_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from  matplotlib.cm import  binary\n",
    "\n",
    "some_digit = digit_X_train.iloc[13361]\n",
    "some_digit_image = some_digit.values.reshape(28, 28)\n",
    "\n",
    "some_digit_recon = digit_X_train_reconstructed[13361]\n",
    "some_digit_image_recon = some_digit_recon.reshape(28, 28)\n",
    "\n",
    "\n",
    "#plt.figure(figsize=(10,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(some_digit_image, cmap = binary,\n",
    "           interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(some_digit_image_recon, cmap = binary,\n",
    "           interpolation=\"nearest\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is our Dimensionality Reduction Useful?\n",
    "  * On Hand Written Digit Recognition dataset (with 784 pixels) we got an F1-Score of 92% on train set\n",
    "  * Let's use Dimensionality reduced (400 feature) dataset and see if we are getting an F1-Score close t0 92% on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stdScaler = StandardScaler()\n",
    "digit_X_train_dim_400 = stdScaler.fit_transform(digit_X_train_dim_400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "              random_state=42, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42, loss='log')\n",
    "sgd_clf.fit(digit_X_train_dim_400, digit_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = sgd_clf.predict(digit_X_train_dim_400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9270033823739077"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(digit_y_train, y_train_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YES, we got it, hence we can use PCA on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental PCA\n",
    "  * One problem with the preceding implementation of PCA is that it requires the whole training set to fit in memory in order for the SVD algorithm to run. **To overcome this memory issue we can use incremental PCA (IPCA) algorithms.** Incremental PCA can take data in mini-batches one mini-batch at a time. This is useful for large training sets, and also to apply PCA online (i.e., on the fly, as new instances arrive). **Please remember to call partial_fit() on IPCA** (insead of fit())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 200)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "n_batches = 100\n",
    "inc_pca = IncrementalPCA(n_components=200)\n",
    "for batch in np.array_split(digit_X_train, n_batches):\n",
    "    inc_pca.partial_fit(batch)\n",
    "\n",
    "digit_X_train_inc = inc_pca.transform(digit_X_train)    \n",
    "digit_X_train_inc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
